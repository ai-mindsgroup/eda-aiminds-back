# üîÑ Fluxo de Ingest√£o de Chunks Anal√≠ticos

## üìã Como Funciona o Sistema (Autom√°tico)

### **1Ô∏è‚É£ CARGA INICIAL (Base Zerada)**

```python
# Exemplo: Novo arquivo CSV
from src.agent.rag_agent import RAGAgent

agent = RAGAgent('rag_agent')

# Carregar CSV
with open('data/creditcard.csv', 'r') as f:
    csv_text = f.read()

# ‚ö° INGEST√ÉO AUTOM√ÅTICA (faz TUDO)
result = agent.ingest_csv_data(
    csv_text=csv_text,
    source_id='creditcard_full'
)
```

**O que acontece automaticamente:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. AN√ÅLISE AUTOM√ÅTICA DO CSV                            ‚îÇ
‚îÇ     - Pandas l√™ o CSV completo                           ‚îÇ
‚îÇ     - Identifica colunas num√©ricas/categ√≥ricas/temporais ‚îÇ
‚îÇ     - Calcula estat√≠sticas (mean, std, min, max, etc.)   ‚îÇ
‚îÇ     - Detecta correla√ß√µes, outliers, distribui√ß√µes       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. CHUNKING EM 2 ETAPAS                                 ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  A) CHUNKS DE DADOS (17.801 chunks)                      ‚îÇ
‚îÇ     - Cada chunk = 20 linhas do CSV                      ‚îÇ
‚îÇ     - Estrat√©gia: CSV_ROW                                ‚îÇ
‚îÇ     - Overlap de 4 linhas                                ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  B) CHUNKS ANAL√çTICOS (6 chunks) ‚Üê AUTOM√ÅTICO!           ‚îÇ
‚îÇ     1. metadata_types           (tipos de dados)         ‚îÇ
‚îÇ     2. metadata_distribution    (distribui√ß√µes, min/max) ‚îÇ
‚îÇ     3. metadata_central_variability (m√©dia, mediana, std)‚îÇ
‚îÇ     4. metadata_frequency_outliers  (valores freq/raros) ‚îÇ
‚îÇ     5. metadata_correlations    (matriz correla√ß√£o)      ‚îÇ
‚îÇ     6. metadata_patterns_clusters (padr√µes temporais)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. GERA√á√ÉO DE EMBEDDINGS                                ‚îÇ
‚îÇ     - Groq/OpenAI transforma cada chunk em vetor (384D)  ‚îÇ
‚îÇ     - Vetores capuram significado sem√¢ntico              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. ARMAZENAMENTO NO SUPABASE                            ‚îÇ
‚îÇ     Tabela: embeddings                                   ‚îÇ
‚îÇ     - chunk_text: conte√∫do                               ‚îÇ
‚îÇ     - embedding: vetor [0.12, 0.45, ...]                 ‚îÇ
‚îÇ     - metadata: { chunk_type, topic, ... }               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ **2Ô∏è‚É£ NOVO DATASET (Vale Refei√ß√£o)**

**Exemplo: CSV de Vale Refei√ß√£o**

```csv
funcionario_id,nome,departamento,valor_refeicao,data_compra,quantidade_tickets
1001,Jo√£o Silva,TI,15.50,2025-01-15,20
1002,Maria Santos,RH,15.50,2025-01-15,22
1003,Pedro Costa,Vendas,18.00,2025-01-16,25
...
```

### **C√≥digo de Ingest√£o (ID√äNTICO!):**

```python
from src.agent.rag_agent import RAGAgent

agent = RAGAgent('rag_agent')

# Carregar CSV de vale refei√ß√£o
with open('data/vale_refeicao.csv', 'r') as f:
    csv_text = f.read()

# ‚ö° MESMA FUN√á√ÉO - Sistema se adapta automaticamente!
result = agent.ingest_csv_data(
    csv_text=csv_text,
    source_id='vale_refeicao_jan2025'  # ‚Üê S√≥ muda o ID
)
```

### **O Sistema Detecta AUTOMATICAMENTE:**

```python
# _generate_metadata_chunks() faz an√°lise inteligente:

# 1. Identifica tipos de dados
numeric_cols = ['funcionario_id', 'valor_refeicao', 'quantidade_tickets']
categorical_cols = ['nome', 'departamento']
datetime_cols = ['data_compra']

# 2. Gera CHUNK 1 (Tipos e Estrutura) - GEN√âRICO!
"""
AN√ÅLISE DE TIPOLOGIA E ESTRUTURA - DATASET: VALE_REFEICAO_JAN2025

ESTRUTURA GERAL:
- Total de registros: 1.250
- Total de colunas: 6
- Colunas num√©ricas: 3
- Colunas categ√≥ricas: 2
- Colunas temporais: 1

COLUNAS NUM√âRICAS (3):
  ‚Ä¢ funcionario_id (int64)
  ‚Ä¢ valor_refeicao (float64)
  ‚Ä¢ quantidade_tickets (int64)

COLUNAS CATEG√ìRICAS (2):
  ‚Ä¢ nome (15 valores √∫nicos)
  ‚Ä¢ departamento (5 valores √∫nicos)
...
"""

# 3. Gera CHUNK 2 (Distribui√ß√µes) - GEN√âRICO!
"""
AN√ÅLISE DE DISTRIBUI√á√ïES E INTERVALOS - DATASET: VALE_REFEICAO_JAN2025

ESTAT√çSTICAS DESCRITIVAS:
funcionario_id    valor_refeicao    quantidade_tickets
count     1250           1250                1250
mean      5625           16.25               22.5
std       3612            2.15                3.8
min       1001           15.50               18
25%       3313           15.50               20
50%       5625           15.50               22
75%       7937           18.00               25
max      10250           20.00               30

INTERVALOS (MIN-MAX):
  ‚Ä¢ valor_refeicao: [15.50, 20.00]
  ‚Ä¢ quantidade_tickets: [18, 30]
...
"""

# 4-6. Demais chunks anal√≠ticos gerados automaticamente!
```

---

## üéØ **COMO O SISTEMA √â GEN√âRICO**

### **C√≥digo-Fonte (src/agent/rag_agent.py, linha 302):**

```python
def _generate_metadata_chunks(self, csv_text: str, source_id: str) -> List[TextChunk]:
    """Sistema GEN√âRICO para QUALQUER CSV."""
    
    # L√™ CSV com Pandas (funciona para QUALQUER estrutura)
    df = pd.read_csv(io.StringIO(csv_text))
    
    # ‚úÖ DETEC√á√ÉO AUTOM√ÅTICA (n√£o precisa saber o dom√≠nio!)
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
    
    # ‚úÖ GERA CHUNKS BASEADO NO QUE ENCONTROU (n√£o hardcoded!)
    
    # Chunk 1: Tipos (funciona para fraude, vale refei√ß√£o, vendas, etc.)
    types_content = f"""
    COLUNAS NUM√âRICAS: {len(numeric_cols)}
    {chr(10).join([f"  ‚Ä¢ {col} ({df[col].dtype})" for col in numeric_cols])}
    
    COLUNAS CATEG√ìRICAS: {len(categorical_cols)}
    {chr(10).join([f"  ‚Ä¢ {col} ({df[col].nunique()} valores √∫nicos)" for col in categorical_cols])}
    """
    
    # Chunk 2: Distribui√ß√µes (calcula automaticamente para QUALQUER coluna num√©rica)
    desc = df[numeric_cols].describe()  # ‚Üê Pandas faz para QUALQUER dataset!
    
    # Chunk 3-6: Correla√ß√µes, outliers, padr√µes (tudo gen√©rico!)
    ...
```

---

## üìä **COMPARA√á√ÉO: 3 Datasets Diferentes**

| Aspecto | Fraude (Cart√£o) | Vale Refei√ß√£o | E-commerce (Vendas) |
|---------|----------------|---------------|---------------------|
| **Colunas** | 31 (Time, V1-V28, Amount, Class) | 6 (funcionario_id, nome, valor, data, etc.) | 12 (produto_id, categoria, preco, qtd, etc.) |
| **Linhas** | 284.808 | 1.250 | 45.600 |
| **Chunks de Dados** | 17.801 | 79 | 2.850 |
| **Chunks Anal√≠ticos** | **6** (gerados automaticamente) | **6** (gerados automaticamente) | **6** (gerados automaticamente) |
| **C√≥digo Python** | `agent.ingest_csv_data(csv, 'fraud')` | `agent.ingest_csv_data(csv, 'vale')` | `agent.ingest_csv_data(csv, 'vendas')` |

**‚ö†Ô∏è O C√ìDIGO √â ID√äNTICO! Sistema se adapta ao conte√∫do.**

---

## üõ†Ô∏è **FLUXO T√âCNICO DETALHADO**

### **Arquivo: src/agent/rag_agent.py**

```python
def ingest_csv_data(self, csv_text: str, source_id: str) -> Dict[str, Any]:
    """M√âTODO PRINCIPAL - Processa QUALQUER CSV."""
    
    # Passo 1: Ingestar dados brutos (linhas do CSV)
    result = self.ingest_text(
        text=csv_text,
        source_id=source_id,
        source_type="csv",
        chunk_strategy=ChunkStrategy.CSV_ROW  # 20 linhas por chunk
    )
    
    # Passo 2: SE ingest√£o OK, gerar chunks anal√≠ticos (AUTOM√ÅTICO!)
    if not result.get("metadata", {}).get("error"):
        metadata_chunks = self._generate_metadata_chunks(csv_text, source_id)
        # ‚Üë Aqui acontece a M√ÅGICA - an√°lise Pandas + gera√ß√£o de 6 chunks
        
        # Gerar embeddings dos chunks anal√≠ticos
        embeddings = self.embedding_generator.generate_embeddings_batch(metadata_chunks)
        
        # Armazenar no Supabase
        self.vector_store.store_embeddings(embeddings, "csv")
    
    return result
```

### **M√©todo _generate_metadata_chunks() - LINHA 302:**

```python
def _generate_metadata_chunks(self, csv_text: str, source_id: str) -> List[TextChunk]:
    """Gera 6 chunks anal√≠ticos para QUALQUER CSV."""
    
    # 1. An√°lise com Pandas (biblioteca universal para CSV)
    df = pd.read_csv(io.StringIO(csv_text))
    
    # 2. Detec√ß√£o autom√°tica de tipos
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    # 3. Gerar 6 chunks com estat√≠sticas (funciona para QUALQUER dataset!)
    chunks = [
        self._create_types_chunk(df, source_id),           # Tipos de dados
        self._create_distribution_chunk(df, source_id),    # Distribui√ß√µes
        self._create_central_chunk(df, source_id),         # M√©dia, mediana
        self._create_outliers_chunk(df, source_id),        # Valores raros
        self._create_correlation_chunk(df, source_id),     # Correla√ß√µes
        self._create_patterns_chunk(df, source_id)         # Padr√µes temporais
    ]
    
    return chunks
```

---

## üöÄ **EXEMPLO PR√ÅTICO: 3 Comandos Diferentes, Mesmo Sistema**

### **1. Fraude (Cart√£o de Cr√©dito):**
```python
agent.ingest_csv_data(csv_text, 'creditcard_full')
# Resultado: 17.801 chunks dados + 6 chunks anal√≠ticos
```

### **2. Vale Refei√ß√£o:**
```python
agent.ingest_csv_data(csv_text, 'vale_refeicao_jan2025')
# Resultado: 79 chunks dados + 6 chunks anal√≠ticos
```

### **3. Vendas E-commerce:**
```python
agent.ingest_csv_data(csv_text, 'vendas_ecommerce_2024')
# Resultado: 2.850 chunks dados + 6 chunks anal√≠ticos
```

**‚úÖ Sistema se adapta automaticamente ao conte√∫do do CSV!**

---

## üí° **PERGUNTAS FREQUENTES**

### ‚ùì "Como o sistema sabe quais estat√≠sticas gerar?"
**R:** Usa Pandas! `df.describe()` funciona para QUALQUER dataset.

### ‚ùì "E se o CSV tiver colunas diferentes?"
**R:** Pandas detecta automaticamente: `select_dtypes(include=[np.number])`.

### ‚ùì "Preciso configurar algo espec√≠fico por dom√≠nio?"
**R:** N√ÉO! Apenas troque o `source_id`. O resto √© autom√°tico.

### ‚ùì "Como responder perguntas espec√≠ficas do dom√≠nio?"
**R:** O LLM interpreta! Exemplo:
- Fraude: "Quais transa√ß√µes s√£o suspeitas?" ‚Üí LLM encontra chunk com Class=1
- Vale: "Qual departamento gasta mais?" ‚Üí LLM encontra chunk com aggrega√ß√£o por departamento

### ‚ùì "Os 6 chunks s√£o sempre os mesmos?"
**R:** SIM! Estrutura fixa, CONTE√öDO din√¢mico baseado no CSV.

---

## üìù **RESUMO EXECUTIVO**

| Item | Descri√ß√£o |
|------|-----------|
| **Entrada** | Qualquer arquivo CSV (fraude, vale, vendas, etc.) |
| **Processamento** | Pandas analisa automaticamente tipos, estat√≠sticas, correla√ß√µes |
| **Sa√≠da** | N chunks de dados + 6 chunks anal√≠ticos (sempre 6!) |
| **Armazenamento** | Supabase (tabela `embeddings`) com metadados |
| **Busca** | RAG encontra chunks relevantes por similaridade sem√¢ntica |
| **Resposta** | LLM interpreta chunks e responde em linguagem natural |

**üéØ Conclus√£o:** Sistema 100% gen√©rico! Basta chamar `ingest_csv_data()` com qualquer CSV.
