# Especifica√ß√£o da Suite de Testes - Etapa 2

**Arquivo:** `test_hybrid_processor_v2_etapa2_completo.py`  
**Data:** 2025-10-21  
**Autor:** GitHub Copilot (GPT-4.1)  
**Status:** ‚úÖ PRONTO PARA EXECU√á√ÉO

---

## üìã Vis√£o Geral

Suite de testes abrangente para validar o **HybridQueryProcessorV2** refatorado, cobrindo:

- ‚úÖ Fragmenta√ß√£o de queries e agrega√ß√£o de resultados
- ‚úÖ Cache e hist√≥rico em tabelas Supabase
- ‚úÖ Fallback acionado apenas quando necess√°rio
- ‚úÖ Simula√ß√£o de limite de tokens GROQ (6000 TPM)
- ‚úÖ Valida√ß√£o de logs estruturados
- ‚úÖ Varia√ß√µes lingu√≠sticas no QueryAnalyzer

---

## üß™ Testes Implementados

### TESTE 1: Fragmenta√ß√£o e Agrega√ß√£o de Resultados

**Objetivo:** Validar que queries grandes (>6000 tokens) s√£o fragmentadas corretamente.

**Cen√°rio:**
```python
# Dataset: 50,000 linhas x 30 colunas
# Query: ~7500 tokens (estoura limite GROQ)
# Esperado: Fragmenta√ß√£o em 2+ partes
```

**Valida√ß√µes:**
- ‚úÖ Query > 6000 tokens √© fragmentada
- ‚úÖ Cada fragmento ‚â§ 6000 tokens
- ‚úÖ Resultados agregados sem perda de informa√ß√£o
- ‚úÖ Resposta final cont√©m an√°lise completa

**Assertions:**
```python
assert fragments_count > 1, "Query grande deve fragmentar"
assert max_fragment_tokens <= 6000, "Respeitar limite GROQ"
assert len(answer) > 100, "Resposta substantiva"
```

**Tempo Esperado:** 15-30s (dataset grande + fragmenta√ß√£o)

---

### TESTE 2: Cache e Hist√≥rico no Supabase

**Objetivo:** Validar persist√™ncia de cache e hist√≥rico na tabela `contexts`.

**Fluxo:**
1. **Primeira execu√ß√£o:** Processa query, gera cache
2. **Segunda execu√ß√£o:** Deve usar cache (speedup 2x+)
3. **Valida√ß√£o Supabase:** Verifica registros na tabela

**Valida√ß√µes:**
- ‚úÖ Primeira execu√ß√£o N√ÉO usa cache
- ‚úÖ Segunda execu√ß√£o USA cache (from_cache=True)
- ‚úÖ Speedup m√≠nimo de 2x
- ‚úÖ Hist√≥rico salvo no Supabase (context_type=CACHE, USER_QUERY)
- ‚úÖ TTL respeitado (24h padr√£o)

**Assertions:**
```python
assert not result1['from_cache'], "Primeira sem cache"
assert result2['from_cache'], "Segunda com cache"
assert elapsed2 < elapsed1 * 0.5, "Cache 2x+ mais r√°pido"
assert len(history) > 0, "Hist√≥rico no Supabase"
```

**Tempo Esperado:**
- Primeira: 4-6s
- Segunda (cache): <2s

---

### TESTE 3: Decis√£o Inteligente de Fallback

**Objetivo:** Validar que fallback √© acionado apenas quando necess√°rio.

**Cen√°rios:**

#### A) Alta cobertura (‚â•80%) ‚Üí RAG ONLY
```python
# Chunks mock: statistics, distribution, correlation, outliers
# Query: "Qual a distribui√ß√£o estat√≠stica dos valores e outliers?"
# Esperado: RAG ONLY (chunks cobrem a query)
```

#### B) Baixa cobertura (<80%) ‚Üí CSV FALLBACK
```python
# Query: "Analise padr√µes temporais em Time e V27 e V28"
# Esperado: CSV FALLBACK (aspectos n√£o cobertos)
```

#### C) Query repetida ‚Üí Sem redund√¢ncia
```python
# Query j√° respondida
# Esperado: Usar chunks existentes, n√£o gerar novos
```

**Valida√ß√µes:**
- ‚úÖ Cobertura ‚â•80% usa RAG ONLY
- ‚úÖ Cobertura <80% usa CSV FALLBACK
- ‚úÖ Chunks existentes usados como guia
- ‚úÖ Gaps preenchidos apenas quando necess√°rio
- ‚úÖ Sem regenera√ß√£o redundante de chunks

**Assertions:**
```python
if coverage >= 80:
    assert strategy == 'rag_only'
    assert not csv_accessed
if coverage < 80:
    assert strategy in ['csv_fallback', 'csv_fragmented']
    assert csv_accessed
```

**Tempo Esperado:** 3-8s por cen√°rio

---

### TESTE 4: Simula√ß√£o de Limite GROQ (6000 TPM)

**Objetivo:** Testar comportamento em diferentes tamanhos de query.

**Casos de Teste:**

| Caso | Tokens | Esperado | Valida√ß√£o |
|------|--------|----------|-----------|
| **Query Pequena** | <2000 | Sem fragmenta√ß√£o | fragments_count ‚â§ 1 |
| **Query M√©dia** | 2000-5000 | Sem fragmenta√ß√£o | fragments_count ‚â§ 1 |
| **Query Grande** | >6000 | Fragmenta√ß√£o obrigat√≥ria | fragments_count ‚â• 2 |

**M√©todo:**
```python
def create_large_query(target_tokens: int) -> str:
    """Cria query com tamanho espec√≠fico em tokens"""
    base = "Analise dataset com features: Time, Amount, V1-V28..."
    padding = "insights adicionais..." * (target / 100)
    return base + padding
```

**Valida√ß√µes:**
- ‚úÖ Query <6000: processamento direto
- ‚úÖ Query >6000: fragmenta√ß√£o autom√°tica
- ‚úÖ Cada fragmento ‚â§ 6000 tokens
- ‚úÖ Resposta final agrega todos os fragmentos

**Assertions:**
```python
if query_tokens > 6000:
    assert fragments_count >= 2
    assert max_fragment_tokens <= 6000
else:
    assert fragments_count <= 1
```

**Tempo Esperado:**
- Pequena: 2-4s
- M√©dia: 5-8s
- Grande: 15-25s

---

### TESTE 5: Valida√ß√£o de Logs Estruturados

**Objetivo:** Garantir logging detalhado em todas as etapas.

**Logs Esperados:**

| Etapa | Pattern | N√≠vel | Exemplo |
|-------|---------|-------|---------|
| In√≠cio | "IN√çCIO" | INFO | `üì• IN√çCIO - Query: Qual a m√©dia...` |
| An√°lise | "An√°lise" | INFO | `üìä An√°lise: SIMPLE \| statistics` |
| Estrat√©gia | "Estrat√©gia" | INFO | `üéØ Estrat√©gia: rag_only` |
| Chunks | "chunks" | INFO | `üì¶ Chunks encontrados: 5` |
| CSV | "CSV" | INFO | `‚úÖ CSV carregado: (1000, 20)` |
| Fragmenta√ß√£o | "fragmentos" | INFO | `üî™ Query fragmentada: 3 partes` |
| Sucesso | "SUCESSO" | INFO | `‚úÖ SUCESSO - Tempo: 5.23s` |

**M√©todo:**
```python
# Capturar logs via handler tempor√°rio
log_capture = StringIO()
handler = logging.StreamHandler(log_capture)
root_logger.addHandler(handler)

# ... executar query ...

log_output = log_capture.getvalue()
assert "IN√çCIO" in log_output
assert "Estrat√©gia" in log_output
# etc...
```

**Valida√ß√µes:**
- ‚úÖ Logs estruturados (JSON quando poss√≠vel)
- ‚úÖ Timestamps em todas as mensagens
- ‚úÖ N√≠veis corretos (INFO, WARNING, ERROR)
- ‚úÖ Cobertura m√≠nima de 70% dos logs esperados

**Assertions:**
```python
coverage = len(logs_found) / len(expected) * 100
assert coverage >= 70, "Cobertura m√≠nima de logs"
```

**Tempo Esperado:** 5-7s

---

### TESTE 6: Varia√ß√µes Lingu√≠sticas no QueryAnalyzer

**Objetivo:** Validar robustez do classificador com portugu√™s variado.

**Casos de Teste:**

#### 1. Estat√≠sticas (SIMPLE)
```python
queries = [
    "Qual a m√©dia de Amount?",          # Formal
    "Me d√° a m√©dia da coluna Amount",   # Informal
    "Calcule o valor m√©dio de Amount",  # T√©cnico
    "Quanto √© a m√©dia dos valores?",    # Coloquial
]
expected: QueryCategory.STATISTICS, QueryComplexity.SIMPLE
```

#### 2. Correla√ß√µes (SIMPLE)
```python
queries = [
    "Correla√ß√£o entre Amount e Time",
    "Amount e Time est√£o correlacionados?",
    "Existe rela√ß√£o entre Amount e Time?",
    "Calcule Pearson entre Amount e Time",
]
expected: QueryCategory.CORRELATION, QueryComplexity.SIMPLE
```

#### 3. Distribui√ß√µes (SIMPLE)
```python
queries = [
    "Distribui√ß√£o de Amount",
    "Como √© a distribui√ß√£o dos valores?",
    "Mostre distribui√ß√£o estat√≠stica",
    "Histograma de Amount",
]
expected: QueryCategory.DISTRIBUTION, QueryComplexity.SIMPLE
```

#### 4. Outliers (SIMPLE)
```python
queries = [
    "Outliers em Amount",
    "Valores at√≠picos na coluna Amount",
    "Anomalias em Amount",
    "Pontos fora da curva em Amount",
]
expected: QueryCategory.OUTLIERS, QueryComplexity.SIMPLE
```

#### 5. Queries Complexas (COMPLEX)
```python
queries = [
    "Analise correla√ß√£o entre Amount, Time e V1-V28...",
    "An√°lise completa: stats, distribui√ß√µes, correla√ß√µes",
    "Padr√µes de fraude atrav√©s de an√°lise multivariada",
]
expected: QueryComplexity.COMPLEX
```

**Valida√ß√µes:**
- ‚úÖ Classifica√ß√£o correta de categoria
- ‚úÖ Classifica√ß√£o correta de complexidade
- ‚úÖ Robustez a varia√ß√µes (formal/informal)
- ‚úÖ Taxa de acerto ‚â•70%

**Assertions:**
```python
accuracy = (passed / total) * 100
assert accuracy >= 70, "Taxa m√≠nima de acerto"
```

**Tempo Esperado:** <1s (apenas an√°lise, sem LLM)

---

## üöÄ Como Executar

### Execu√ß√£o Completa

```powershell
python test_hybrid_processor_v2_etapa2_completo.py
```

### Execu√ß√£o Individual (para debug)

```python
import asyncio
from test_hybrid_processor_v2_etapa2_completo import test_01_query_fragmentation_and_aggregation

# Rodar apenas teste 1
asyncio.run(test_01_query_fragmentation_and_aggregation())
```

### Com Pytest

```powershell
pytest test_hybrid_processor_v2_etapa2_completo.py -v -s
```

---

## üìä Resultados Esperados

### Taxa de Sucesso

```
Target: 100% (6/6 testes)
M√≠nimo aceit√°vel: 83% (5/6 testes)
```

### Tempo de Execu√ß√£o

| Teste | Tempo Esperado |
|-------|----------------|
| 1. Fragmenta√ß√£o | 15-30s |
| 2. Cache | 6-8s |
| 3. Fallback | 10-20s |
| 4. Limite GROQ | 25-35s |
| 5. Logs | 5-7s |
| 6. Lingu√≠stica | <1s |
| **TOTAL** | **60-100s** |

### Sa√≠da Esperada

```
================================================================================
üß™ SUITE DE TESTES COMPLETA - ETAPA 2
   HybridQueryProcessorV2 + FastQueryFragmenter + Supabase
================================================================================
‚è±Ô∏è In√≠cio: 2025-10-21 01:45:00

################################################################################
# TESTE 1/6: Fragmenta√ß√£o e Agrega√ß√£o
################################################################################
...
‚úÖ TESTE 1 PASSOU - Fragmenta√ß√£o e agrega√ß√£o funcionando

################################################################################
# TESTE 2/6: Cache e Hist√≥rico Supabase
################################################################################
...
‚úÖ TESTE 2 PASSOU - Cache e hist√≥rico funcionando

... (continua para todos os testes)

================================================================================
üìä SUM√ÅRIO DOS TESTES - ETAPA 2
================================================================================
Fragmenta√ß√£o e Agrega√ß√£o........................... ‚úÖ PASSOU
Cache e Hist√≥rico Supabase......................... ‚úÖ PASSOU
Fallback Inteligente............................... ‚úÖ PASSOU
Limite GROQ (6000 TPM)............................. ‚úÖ PASSOU
Logs Estruturados.................................. ‚úÖ PASSOU
Varia√ß√µes Lingu√≠sticas............................. ‚úÖ PASSOU
================================================================================
‚è±Ô∏è Tempo total: 78.34s
üìà Taxa de sucesso: 6/6 (100%)

üéâ TODOS OS TESTES PASSARAM!
```

---

## üêõ Troubleshooting

### Problema: Rate Limit GROQ

**Sintoma:**
```
Error code: 413 - Request too large
Limit 6000, Requested 6582
```

**Solu√ß√£o:**
1. Verificar se FastQueryFragmenter est√° ativo
2. Confirmar `token_budget=6000` no processor
3. Validar que queries grandes est√£o sendo fragmentadas

### Problema: Cache n√£o ativa

**Sintoma:**
```
‚ö†Ô∏è Cache n√£o ativado (pode ser esperado em ambiente de teste)
```

**Causa:** Session ID diferente ou tabela `contexts` n√£o criada

**Solu√ß√£o:**
1. Usar mesmo `session_id` na segunda execu√ß√£o
2. Rodar migrations: `python scripts/run_migrations.py`
3. Verificar conex√£o Supabase: `python check_db.py`

### Problema: Chunks n√£o encontrados (Teste 3)

**Sintoma:**
```
Cobertura: 0.0%
Estrat√©gia: csv_fallback (esperado: rag_only)
```

**Causa:** Chunks mock n√£o inseridos no vector store

**Solu√ß√£o:**
```python
# Confirmar que populate_chunks_in_vectorstore foi executado
await populate_chunks_in_vectorstore(vector_store, mock_chunks)
await asyncio.sleep(1)  # Aguardar propaga√ß√£o
```

### Problema: Logs n√£o capturados (Teste 5)

**Sintoma:**
```
Cobertura de logs: 20% (2/10)
```

**Causa:** Handler de log n√£o configurado corretamente

**Solu√ß√£o:**
```python
# Garantir que handler est√° no root logger
root_logger = logging.getLogger()  # SEM nome
root_logger.addHandler(handler)
```

---

## üìö Depend√™ncias

### M√≥dulos Python
```python
asyncio, pandas, numpy, hashlib, json, datetime, pathlib, logging
```

### M√≥dulos Internos
```python
src.agent.hybrid_query_processor_v2
src.agent.query_analyzer
src.agent.fast_query_fragmenter
src.embeddings.vector_store
src.embeddings.generator
src.memory.supabase_memory
src.llm.manager
src.utils.logging_config
```

### Configura√ß√µes Necess√°rias
- ‚úÖ Supabase configurado (`.env` com credenciais)
- ‚úÖ Migrations executadas (`python scripts/run_migrations.py`)
- ‚úÖ GROQ API key configurada
- ‚úÖ Python 3.10+

---

## üîÑ Manuten√ß√£o

### Adicionar Novo Teste

```python
async def test_07_meu_novo_teste():
    """Descri√ß√£o do teste."""
    print(f"\n{'='*80}")
    print("üß™ TESTE 7: MEU NOVO TESTE")
    print(f"{'='*80}")
    
    # Setup
    # ... c√≥digo ...
    
    # Valida√ß√µes
    assert resultado == esperado
    
    print("\n‚úÖ TESTE 7 PASSOU")
    return resultado

# Adicionar em run_all_etapa2_tests():
tests = [
    # ... testes existentes ...
    ("Meu Novo Teste", test_07_meu_novo_teste),
]
```

### Atualizar Expectativas

Editar se√ß√£o de cada teste para refletir mudan√ßas na arquitetura.

---

## üìñ Refer√™ncias

- [HybridQueryProcessorV2 Architecture](HYBRID_PROCESSOR_V2_ARCHITECTURE.md)
- [FastQueryFragmenter](../src/agent/fast_query_fragmenter.py)
- [QueryAnalyzer](../src/agent/query_analyzer.py)
- [Supabase Memory](../src/memory/supabase_memory.py)

---

**√öltima atualiza√ß√£o:** 2025-10-21 02:00 BRT  
**Status:** ‚úÖ PRONTO PARA EXECU√á√ÉO  
**Cobertura:** 6 testes / 100% das funcionalidades da Etapa 2
