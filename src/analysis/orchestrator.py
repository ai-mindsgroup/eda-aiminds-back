"""
Orquestrador de An√°lises - Coordena√ß√£o Modular e Inteligente

Este m√≥dulo coordena a execu√ß√£o de m√∫ltiplos analisadores especializados
de forma inteligente, baseando-se na classifica√ß√£o de inten√ß√£o via LLM.

Autor: EDA AI Minds Team
Data: 2025-10-16
Vers√£o: 3.0.0
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
import pandas as pd
import logging
from datetime import datetime

from src.analysis.intent_classifier import IntentClassifier, AnalysisIntent, IntentClassificationResult
from src.analysis.statistical_analyzer import StatisticalAnalyzer, StatisticalAnalysisResult
from src.analysis.frequency_analyzer import FrequencyAnalyzer, FrequencyAnalysisResult
from src.analysis.temporal_analyzer import TemporalAnalyzer, TemporalAnalysisResult
from src.analysis.clustering_analyzer import ClusteringAnalyzer, ClusteringAnalysisResult


@dataclass
class OrchestrationResult:
    """
    Resultado da orquestra√ß√£o de an√°lises.
    
    Attributes:
        intent_classification: Classifica√ß√£o de inten√ß√£o original
        analysis_results: Resultados de cada an√°lise executada
        combined_interpretation: Interpreta√ß√£o combinada
        execution_order: Ordem de execu√ß√£o dos m√≥dulos
        metadata: Metadados de orquestra√ß√£o
    """
    intent_classification: IntentClassificationResult
    analysis_results: Dict[str, Any] = field(default_factory=dict)
    combined_interpretation: str = ""
    execution_order: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_markdown(self) -> str:
        """Gera relat√≥rio consolidado em Markdown."""
        md = "# Relat√≥rio de An√°lise Integrada\n\n"
        
        # Inten√ß√£o detectada
        md += "## Inten√ß√£o Detectada\n\n"
        md += f"**An√°lise principal:** {self.intent_classification.primary_intent.value}\n"
        if self.intent_classification.secondary_intents:
            intents = ", ".join([i.value for i in self.intent_classification.secondary_intents])
            md += f"**An√°lises complementares:** {intents}\n"
        md += f"**Confian√ßa:** {self.intent_classification.confidence:.1%}\n\n"
        md += f"*{self.intent_classification.reasoning}*\n\n"
        
        md += "---\n\n"
        
        # Resultados de cada an√°lise
        for analyzer_name, result in self.analysis_results.items():
            if hasattr(result, 'to_markdown'):
                md += result.to_markdown() + "\n\n---\n\n"
        
        # Interpreta√ß√£o combinada
        if self.combined_interpretation:
            md += "## S√≠ntese e Conclus√µes\n\n"
            md += self.combined_interpretation + "\n\n"
        
        # Metadados
        md += "## Metadados de Execu√ß√£o\n\n"
        md += f"- **M√≥dulos executados:** {', '.join(self.execution_order)}\n"
        md += f"- **Tempo total:** {self.metadata.get('total_time_ms', 0):.0f}ms\n"
        md += f"- **Timestamp:** {self.metadata.get('timestamp', 'N/A')}\n"
        
        return md


class AnalysisOrchestrator:
    """
    Orquestrador inteligente de an√°lises modulares.
    
    PRINC√çPIOS:
    1. Classifica√ß√£o de inten√ß√£o via LLM (zero hard-coding)
    2. Execu√ß√£o condicional de m√≥dulos especializados
    3. Combina√ß√£o inteligente de resultados
    4. Extens√≠vel para novos tipos de an√°lise
    
    Exemplo:
        >>> orchestrator = AnalysisOrchestrator(llm)
        >>> result = orchestrator.orchestrate("Qual a dispers√£o dos dados?", df)
        >>> print(result.to_markdown())
    """
    
    def __init__(self, llm, logger: Optional[logging.Logger] = None):
        """
        Inicializa orquestrador.
        
        Args:
            llm: Inst√¢ncia de LLM para classifica√ß√£o de inten√ß√£o
            logger: Logger opcional
        """
        self.llm = llm
        self.logger = logger or logging.getLogger(__name__)
        
        # Inicializar classificador e analisadores
        self.intent_classifier = IntentClassifier(llm, logger)
        self.statistical_analyzer = StatisticalAnalyzer(logger)
        self.frequency_analyzer = FrequencyAnalyzer(logger)
        self.temporal_analyzer = TemporalAnalyzer(logger)
        self.clustering_analyzer = ClusteringAnalyzer(logger)
        
        # Mapeamento de inten√ß√µes para analisadores
        self._intent_to_analyzer = {
            AnalysisIntent.STATISTICAL: self._run_statistical_analysis,
            AnalysisIntent.FREQUENCY: self._run_frequency_analysis,
            AnalysisIntent.TEMPORAL: self._run_temporal_analysis,
            AnalysisIntent.CLUSTERING: self._run_clustering_analysis,
            AnalysisIntent.GENERAL: self._run_general_analysis
        }
        
        self.logger.info("‚úÖ AnalysisOrchestrator inicializado")
    
    def orchestrate(
        self,
        query: str,
        df: pd.DataFrame,
        context: Optional[Dict[str, Any]] = None
    ) -> OrchestrationResult:
        """
        Orquestra execu√ß√£o de an√°lises baseada na query do usu√°rio.
        
        FLUXO:
        1. Classifica inten√ß√£o via LLM
        2. Identifica m√≥dulos necess√°rios
        3. Executa an√°lises em ordem apropriada
        4. Combina resultados
        5. Gera interpreta√ß√£o integrada
        
        Args:
            query: Query do usu√°rio
            df: DataFrame a analisar
            context: Contexto adicional
            
        Returns:
            Resultado consolidado de todas an√°lises
        """
        start_time = datetime.now()
        
        try:
            self.logger.info(f"üéØ Orquestrando an√°lise para query: {query[:80]}...")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 1. CLASSIFICAR INTEN√á√ÉO (LLM decide tudo)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            intent_result = self.intent_classifier.classify(query, context)
            
            self.logger.info(
                f"Inten√ß√£o classificada: {intent_result.primary_intent.value} "
                f"(confian√ßa: {intent_result.confidence:.2f})"
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 2. IDENTIFICAR M√ìDULOS NECESS√ÅRIOS
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            intents_to_execute = [intent_result.primary_intent]
            intents_to_execute.extend(intent_result.secondary_intents)
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 3. EXECUTAR AN√ÅLISES
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            result = OrchestrationResult(intent_classification=intent_result)
            
            for intent in intents_to_execute:
                analyzer_func = self._intent_to_analyzer.get(intent)
                
                if analyzer_func:
                    try:
                        self.logger.info(f"Executando an√°lise: {intent.value}")
                        
                        analysis_result = analyzer_func(df, query, context)
                        
                        if analysis_result:
                            analyzer_name = intent.value
                            result.analysis_results[analyzer_name] = analysis_result
                            result.execution_order.append(analyzer_name)
                            
                            self.logger.info(f"‚úÖ An√°lise {intent.value} conclu√≠da")
                    
                    except Exception as e:
                        self.logger.error(f"Erro na an√°lise {intent.value}: {e}", exc_info=True)
                        # Continua para pr√≥ximas an√°lises
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 4. COMBINAR RESULTADOS E GERAR INTERPRETA√á√ÉO INTEGRADA
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            result.combined_interpretation = self._generate_combined_interpretation(
                query, result
            )
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 5. METADADOS
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            total_time = (datetime.now() - start_time).total_seconds() * 1000
            
            result.metadata = {
                "total_time_ms": total_time,
                "modules_executed": len(result.execution_order),
                "timestamp": datetime.now().isoformat(),
                "dataframe_shape": df.shape
            }
            
            self.logger.info(
                f"üéØ Orquestra√ß√£o conclu√≠da: {len(result.execution_order)} m√≥dulos "
                f"executados em {total_time:.0f}ms"
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"Erro na orquestra√ß√£o: {e}", exc_info=True)
            raise
    
    def _run_statistical_analysis(
        self,
        df: pd.DataFrame,
        query: str,
        context: Optional[Dict] = None
    ) -> StatisticalAnalysisResult:
        """Executa an√°lise estat√≠stica."""
        return self.statistical_analyzer.analyze(df)
    
    def _run_frequency_analysis(
        self,
        df: pd.DataFrame,
        query: str,
        context: Optional[Dict] = None
    ) -> FrequencyAnalysisResult:
        """Executa an√°lise de frequ√™ncia."""
        return self.frequency_analyzer.analyze(df)
    
    def _run_temporal_analysis(
        self,
        df: pd.DataFrame,
        query: str,
        context: Optional[Dict] = None
    ) -> Optional[TemporalAnalysisResult]:
        """Executa an√°lise temporal."""
        # Detectar colunas temporais
        from analysis.temporal_detection import TemporalColumnDetector
        
        detector = TemporalColumnDetector()
        detection_results = detector.detect(df)
        temporal_cols = detector.get_detected_columns(detection_results)
        
        if not temporal_cols:
            self.logger.warning("Nenhuma coluna temporal detectada")
            return None
        
        # Analisar primeira coluna temporal encontrada
        return self.temporal_analyzer.analyze(df, temporal_cols[0])
    
    def _run_clustering_analysis(
        self,
        df: pd.DataFrame,
        query: str,
        context: Optional[Dict] = None
    ) -> ClusteringAnalysisResult:
        """Executa an√°lise de clustering."""
        # Usar KMeans com 3 clusters como padr√£o
        # TODO: Usar LLM para extrair par√¢metros da query
        return self.clustering_analyzer.analyze(df, n_clusters=3)
    
    def _run_general_analysis(
        self,
        df: pd.DataFrame,
        query: str,
        context: Optional[Dict] = None
    ) -> StatisticalAnalysisResult:
        """Executa an√°lise geral (fallback)."""
        return self.statistical_analyzer.analyze(df)
    
    def _generate_combined_interpretation(
        self,
        query: str,
        result: OrchestrationResult
    ) -> str:
        """
        Gera interpreta√ß√£o combinada de m√∫ltiplas an√°lises via LLM.
        
        Args:
            query: Query original do usu√°rio
            result: Resultado da orquestra√ß√£o
            
        Returns:
            Interpreta√ß√£o integrada
        """
        try:
            # Extrair interpreta√ß√µes individuais
            interpretations = []
            for analyzer_name, analysis_result in result.analysis_results.items():
                if hasattr(analysis_result, 'interpretation'):
                    interp = analysis_result.interpretation
                    if interp:
                        interpretations.append(f"**{analyzer_name}**: {interp}")
            
            if not interpretations:
                return "An√°lise conclu√≠da. Consulte se√ß√µes acima para detalhes."
            
            # Usar LLM para sintetizar
            from langchain.schema import HumanMessage, SystemMessage
            
            system_prompt = """
Voc√™ √© um agente EDA expert em s√≠ntese de an√°lises.
Sua tarefa √© combinar m√∫ltiplas interpreta√ß√µes anal√≠ticas em uma s√≠ntese coerente e contextual.

Regras:
1. Mantenha foco na pergunta do usu√°rio
2. Destaque insights mais relevantes
3. Identifique padr√µes cruzados entre an√°lises
4. Seja conciso (m√°ximo 3 par√°grafos)
5. Sugira pr√≥ximos passos integrados
"""
            
            user_prompt = f"""
Pergunta do usu√°rio: {query}

Interpreta√ß√µes anal√≠ticas:
{chr(10).join(interpretations)}

Sintetize essas interpreta√ß√µes de forma coerente e contextual.
"""
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm.invoke(messages)
            return response.content.strip()
            
        except Exception as e:
            self.logger.error(f"Erro ao gerar interpreta√ß√£o combinada: {e}")
            return "An√°lise conclu√≠da. Consulte se√ß√µes acima para detalhes."
    
    def orchestrate_v3_direct(
        self,
        intent_result: Dict[str, float],
        df: pd.DataFrame,
        confidence_threshold: float = 0.6
    ) -> Dict[str, Any]:
        """
        üî• V3.0: Orquestra√ß√£o direta baseada em dict de inten√ß√µes.
        
        Usado para integra√ß√£o com rag_data_agent.py que j√° possui
        classifica√ß√£o de inten√ß√£o pr√©via.
        
        Args:
            intent_result: Dict {intent_type: confidence_score}
                          Ex: {"STATISTICAL": 0.92, "FREQUENCY": 0.75}
            df: DataFrame a analisar
            confidence_threshold: Threshold m√≠nimo de confian√ßa (padr√£o: 0.6)
            
        Returns:
            Dict estruturado com resultados:
            {
                "results": {
                    "statistical": {...},
                    "frequency": {...}
                },
                "execution_order": ["statistical", "frequency"],
                "metadata": {
                    "total_time_ms": 145.2,
                    "modules_executed": 2,
                    "timestamp": "2025-10-17T10:30:00"
                }
            }
        """
        start_time = datetime.now()
        
        try:
            self.logger.debug(f"üéØ Orquestra√ß√£o V3 direta iniciada com {len(intent_result)} inten√ß√µes")
            
            results = {}
            execution_order = []
            
            # Mapear strings de inten√ß√£o para AnalysisIntent enum
            intent_map = {
                "STATISTICAL": AnalysisIntent.STATISTICAL,
                "FREQUENCY": AnalysisIntent.FREQUENCY,
                "TEMPORAL": AnalysisIntent.TEMPORAL,
                "CLUSTERING": AnalysisIntent.CLUSTERING,
                "CORRELATION": AnalysisIntent.CORRELATION,
                "OUTLIERS": AnalysisIntent.OUTLIERS,
                "COMPARISON": AnalysisIntent.COMPARISON,
                "GENERAL": AnalysisIntent.GENERAL
            }
            
            # Executar an√°lises conforme confian√ßa
            for analysis_type, confidence in intent_result.items():
                if confidence < confidence_threshold:
                    self.logger.debug(f"‚è≠Ô∏è Ignorando {analysis_type} (confian√ßa {confidence:.2f} < {confidence_threshold})")
                    continue
                
                # Converter para enum
                intent_enum = intent_map.get(analysis_type.upper())
                if not intent_enum:
                    self.logger.warning(f"‚ö†Ô∏è Tipo de an√°lise desconhecido: {analysis_type}")
                    continue
                
                # Obter fun√ß√£o do analyzer
                analyzer_func = self._intent_to_analyzer.get(intent_enum)
                
                if analyzer_func:
                    try:
                        self.logger.info(f"‚ñ∂Ô∏è Executando an√°lise: {analysis_type}")
                        
                        analysis_result = analyzer_func(df, query="", context=None)
                        
                        if analysis_result:
                            analyzer_key = analysis_type.lower()
                            
                            # Converter resultado para dict se poss√≠vel
                            if hasattr(analysis_result, 'to_dict'):
                                results[analyzer_key] = analysis_result.to_dict()
                            elif hasattr(analysis_result, '__dict__'):
                                results[analyzer_key] = analysis_result.__dict__
                            else:
                                results[analyzer_key] = str(analysis_result)
                            
                            execution_order.append(analyzer_key)
                            self.logger.info(f"‚úÖ An√°lise {analysis_type} conclu√≠da")
                    
                    except Exception as e:
                        self.logger.error(f"‚ùå Erro na an√°lise {analysis_type}: {e}", exc_info=True)
                        results[analysis_type.lower()] = {"error": str(e)}
            
            # Metadados
            total_time = (datetime.now() - start_time).total_seconds() * 1000
            
            response = {
                "results": results,
                "execution_order": execution_order,
                "metadata": {
                    "total_time_ms": total_time,
                    "modules_executed": len(execution_order),
                    "timestamp": datetime.now().isoformat(),
                    "dataframe_shape": list(df.shape)
                }
            }
            
            self.logger.info(
                f"üéØ Orquestra√ß√£o V3 conclu√≠da: {len(execution_order)} m√≥dulos "
                f"executados em {total_time:.0f}ms"
            )
            
            return response
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro cr√≠tico na orquestra√ß√£o V3: {e}", exc_info=True)
            return {
                "results": {},
                "execution_order": [],
                "metadata": {
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
            }
