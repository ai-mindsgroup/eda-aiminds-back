"""Sistema de Prompts Din√¢micos e Adaptativos

Este m√≥dulo fornece gera√ß√£o din√¢mica de prompts baseada em:
- Estrutura real do dataset (dtypes, shape, colunas)
- Contexto da pergunta do usu√°rio
- Hist√≥rico conversacional
- Inten√ß√£o detectada

ZERO hardcoding de estruturas espec√≠ficas de dados.
Totalmente adapt√°vel a qualquer dataset CSV gen√©rico.

Autor: EDA AI Minds Team
Data: 2025-10-18
Vers√£o: 4.0.0
"""

from __future__ import annotations
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import pandas as pd
from datetime import datetime


@dataclass
class DatasetContext:
    """Contexto completo do dataset atual."""
    file_path: str
    shape: tuple
    columns: List[str]
    dtypes: Dict[str, str]
    numeric_columns: List[str]
    categorical_columns: List[str]
    temporal_columns: List[str]
    boolean_columns: List[str]
    missing_values: Dict[str, int]
    memory_usage_mb: float
    row_count: int
    column_count: int
    
    @classmethod
    def from_dataframe(cls, df: pd.DataFrame, file_path: str = "unknown") -> DatasetContext:
        """Cria contexto a partir de um DataFrame."""
        dtypes_dict = df.dtypes.astype(str).to_dict()
        
        # Classifica√ß√£o autom√°tica de tipos
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        temporal_cols = df.select_dtypes(include=['datetime', 'timedelta']).columns.tolist()
        boolean_cols = df.select_dtypes(include=['bool']).columns.tolist()
        
        missing = df.isnull().sum().to_dict()
        memory_mb = df.memory_usage(deep=True).sum() / (1024 ** 2)
        
        return cls(
            file_path=file_path,
            shape=df.shape,
            columns=df.columns.tolist(),
            dtypes=dtypes_dict,
            numeric_columns=numeric_cols,
            categorical_columns=categorical_cols,
            temporal_columns=temporal_cols,
            boolean_columns=boolean_cols,
            missing_values=missing,
            memory_usage_mb=memory_mb,
            row_count=len(df),
            column_count=len(df.columns)
        )


class DynamicPromptGenerator:
    """Gerador de prompts completamente din√¢mico e adaptativo."""
    
    def __init__(self):
        """Inicializa o gerador."""
        self.last_context: Optional[DatasetContext] = None
    
    def generate_system_prompt(
        self,
        dataset_context: DatasetContext,
        analysis_intent: str = "general",
        additional_capabilities: List[str] = None
    ) -> str:
        """
        Gera prompt de sistema din√¢mico baseado no dataset real.
        
        Args:
            dataset_context: Contexto completo do dataset
            analysis_intent: Inten√ß√£o da an√°lise (statistical, temporal, etc)
            additional_capabilities: Capacidades adicionais do agente
            
        Returns:
            Prompt de sistema personalizado
        """
        self.last_context = dataset_context
        
        # Construir descri√ß√£o din√¢mica do dataset
        dataset_description = self._build_dataset_description(dataset_context)
        
        # Construir capacidades anal√≠ticas baseadas no tipo de dados
        analytical_capabilities = self._build_analytical_capabilities(dataset_context)
        
        # Construir diretrizes espec√≠ficas para o intent
        intent_guidelines = self._build_intent_guidelines(analysis_intent, dataset_context)
        
        # Montar prompt completo
        system_prompt = f"""ü§ñ **AGENTE EDA - An√°lise Explorat√≥ria de Dados**

üìä **DATASET ATUAL**
{dataset_description}

üß† **CAPACIDADES ANAL√çTICAS DISPON√çVEIS**
{analytical_capabilities}

üéØ **DIRETRIZES PARA AN√ÅLISE ATUAL**
{intent_guidelines}

‚ö° **INSTRU√á√ïES OPERACIONAIS**

1. **PRECIS√ÉO ABSOLUTA**: 
   - Use APENAS os dados reais fornecidos
   - Cite n√∫meros espec√≠ficos, n√£o aproxima√ß√µes
   - Quando incerto, declare explicitamente

2. **COBERTURA COMPLETA**:
   - Analise TODAS as colunas relevantes para a pergunta
   - Considere TODAS as linhas, exceto quando amostragem for solicitada
   - Identifique padr√µes globais E locais

3. **CLAREZA E DID√ÅTICA**:
   - Explique conceitos t√©cnicos quando necess√°rio
   - Use tabelas Markdown para compara√ß√µes
   - Destaque insights principais com **negrito**
   - Finalize sempre com "Se precisar de mais detalhes, √© s√≥ perguntar!"

4. **CONTEXTUALIZA√á√ÉO**:
   - Sempre inicie com: "**Pergunta feita:** [pergunta]"
   - Referencie an√°lises anteriores se houver hist√≥rico
   - Sugira an√°lises complementares relevantes

5. **INTEGRIDADE DOS DADOS**:
   - Mencione valores ausentes se relevantes
   - Identifique limita√ß√µes dos dados
   - Alerte sobre poss√≠veis vieses

üö´ **PROIBI√á√ïES**:
- N√ÉO invente dados que n√£o existem
- N√ÉO assuma caracter√≠sticas n√£o verificadas
- N√ÉO use respostas gen√©ricas de conceitos
- N√ÉO ignore colunas dispon√≠veis sem justificativa

üìù **FORMATO DE RESPOSTA**:
- Estruture em se√ß√µes claras com t√≠tulos
- Use listas para itens m√∫ltiplos
- Inclua tabelas quando comparar valores
- Destaque n√∫meros e m√©tricas chave
"""
        
        return system_prompt
    
    def _build_dataset_description(self, ctx: DatasetContext) -> str:
        """Constr√≥i descri√ß√£o din√¢mica do dataset."""
        desc = f"""
- **Arquivo**: `{ctx.file_path}`
- **Dimens√µes**: {ctx.row_count:,} linhas √ó {ctx.column_count} colunas
- **Mem√≥ria**: {ctx.memory_usage_mb:.2f} MB

**Estrutura de Colunas:**
"""
        
        if ctx.numeric_columns:
            desc += f"\n- **Num√©ricas ({len(ctx.numeric_columns)})**: {', '.join(f'`{col}`' for col in ctx.numeric_columns[:10])}"
            if len(ctx.numeric_columns) > 10:
                desc += f" ... e mais {len(ctx.numeric_columns) - 10}"
        
        if ctx.categorical_columns:
            desc += f"\n- **Categ√≥ricas ({len(ctx.categorical_columns)})**: {', '.join(f'`{col}`' for col in ctx.categorical_columns[:5])}"
            if len(ctx.categorical_columns) > 5:
                desc += f" ... e mais {len(ctx.categorical_columns) - 5}"
        
        if ctx.temporal_columns:
            desc += f"\n- **Temporais ({len(ctx.temporal_columns)})**: {', '.join(f'`{col}`' for col in ctx.temporal_columns)}"
        
        if ctx.boolean_columns:
            desc += f"\n- **Booleanas ({len(ctx.boolean_columns)})**: {', '.join(f'`{col}`' for col in ctx.boolean_columns)}"
        
        # Valores ausentes
        missing_cols = {col: count for col, count in ctx.missing_values.items() if count > 0}
        if missing_cols:
            desc += f"\n\n**Valores Ausentes:**"
            for col, count in list(missing_cols.items())[:5]:
                pct = (count / ctx.row_count) * 100
                desc += f"\n- `{col}`: {count:,} ({pct:.2f}%)"
            if len(missing_cols) > 5:
                desc += f"\n- ... e mais {len(missing_cols) - 5} colunas com dados ausentes"
        
        return desc
    
    def _build_analytical_capabilities(self, ctx: DatasetContext) -> str:
        """Constr√≥i lista de capacidades baseada no tipo de dados dispon√≠vel."""
        capabilities = []
        
        if ctx.numeric_columns:
            capabilities.append("""
**An√°lise Estat√≠stica Descritiva**:
- Medidas de tend√™ncia central (m√©dia, mediana, moda)
- Medidas de dispers√£o (desvio padr√£o, vari√¢ncia, IQR)
- Intervalos (m√≠nimo, m√°ximo, range)
- Percentis e quartis
- Assimetria e curtose""")
        
        if len(ctx.numeric_columns) >= 2:
            capabilities.append("""
**An√°lise de Correla√ß√£o**:
- Matriz de correla√ß√£o entre vari√°veis num√©ricas
- Identifica√ß√£o de rela√ß√µes lineares
- Detec√ß√£o de multicolinearidade""")
        
        if ctx.categorical_columns:
            capabilities.append("""
**An√°lise de Frequ√™ncia**:
- Valores mais/menos frequentes
- Distribui√ß√µes categ√≥ricas
- Tabelas de conting√™ncia
- An√°lise de propor√ß√µes""")
        
        if ctx.temporal_columns:
            capabilities.append("""
**An√°lise Temporal**:
- Identifica√ß√£o de tend√™ncias
- Detec√ß√£o de sazonalidade
- An√°lise de padr√µes temporais
- Evolu√ß√£o de m√©tricas ao longo do tempo""")
        
        capabilities.append("""
**Detec√ß√£o de Anomalias**:
- Identifica√ß√£o de outliers (Z-score, IQR)
- An√°lise de valores at√≠picos
- Impacto de outliers nas estat√≠sticas""")
        
        if ctx.row_count > 100:
            capabilities.append("""
**An√°lise de Agrupamentos**:
- Identifica√ß√£o de clusters naturais
- Segmenta√ß√£o de dados
- An√°lise de padr√µes de similaridade""")
        
        capabilities.append("""
**Visualiza√ß√µes Din√¢micas**:
- Histogramas para distribui√ß√µes
- Gr√°ficos de dispers√£o para rela√ß√µes
- Boxplots para compara√ß√µes
- Heatmaps para correla√ß√µes""")
        
        return "\n".join(capabilities)
    
    def _build_intent_guidelines(self, intent: str, ctx: DatasetContext) -> str:
        """Constr√≥i diretrizes espec√≠ficas baseadas na inten√ß√£o detectada."""
        intent_map = {
            "statistical": self._guidelines_statistical(ctx),
            "frequency": self._guidelines_frequency(ctx),
            "temporal": self._guidelines_temporal(ctx),
            "correlation": self._guidelines_correlation(ctx),
            "outliers": self._guidelines_outliers(ctx),
            "clustering": self._guidelines_clustering(ctx),
            "comparison": self._guidelines_comparison(ctx),
            "visualization": self._guidelines_visualization(ctx),
            "general": self._guidelines_general(ctx)
        }
        
        return intent_map.get(intent.lower(), intent_map["general"])
    
    def _guidelines_statistical(self, ctx: DatasetContext) -> str:
        """Diretrizes para an√°lise estat√≠stica descritiva."""
        cols = ', '.join(f'`{c}`' for c in ctx.numeric_columns[:5])
        if len(ctx.numeric_columns) > 5:
            cols += f" ... ({len(ctx.numeric_columns)} no total)"
        
        return f"""
**An√°lise Estat√≠stica Descritiva Solicitada**

Para as colunas num√©ricas dispon√≠veis ({cols}):

1. **Calcule e reporte**:
   - M√©dia, mediana e moda
   - Desvio padr√£o e vari√¢ncia
   - Valores m√≠nimo e m√°ximo
   - Quartis (Q1, Q2, Q3) e IQR
   
2. **Interprete os resultados**:
   - Compare m√©dia vs mediana (indica assimetria?)
   - Desvio padr√£o alto/baixo (o que significa?)
   - Range dos dados (escala de varia√ß√£o)
   
3. **Identifique caracter√≠sticas**:
   - Distribui√ß√µes sim√©tricas vs assim√©tricas
   - Presen√ßa de valores extremos
   - Variabilidade relativa entre colunas"""
    
    def _guidelines_frequency(self, ctx: DatasetContext) -> str:
        """Diretrizes para an√°lise de frequ√™ncia."""
        return f"""
**An√°lise de Frequ√™ncia e Distribui√ß√£o Solicitada**

Dataset possui {ctx.column_count} colunas para an√°lise.

1. **Para colunas categ√≥ricas**:
   - Liste valores √∫nicos e suas contagens
   - Identifique os TOP 10 valores mais frequentes
   - Identifique valores raros (frequ√™ncia < 1%)
   - Calcule propor√ß√µes relativas

2. **Para colunas num√©ricas**:
   - Agrupe em bins/intervalos apropriados
   - Gere distribui√ß√£o de frequ√™ncias
   - Identifique modas (picos de frequ√™ncia)
   - Sugira visualiza√ß√£o (histograma)

3. **Insights esperados**:
   - Distribui√ß√£o balanceada ou desbalanceada?
   - Valores dominantes?
   - Presen√ßa de valores √∫nicos/raros significativos?"""
    
    def _guidelines_temporal(self, ctx: DatasetContext) -> str:
        """Diretrizes para an√°lise temporal."""
        if ctx.temporal_columns:
            temp_cols = ', '.join(f'`{c}`' for c in ctx.temporal_columns)
            return f"""
**An√°lise Temporal Solicitada**

Colunas temporais dispon√≠veis: {temp_cols}

1. **Identifique padr√µes**:
   - Tend√™ncias (crescimento, decl√≠nio, estabilidade)
   - Sazonalidade (padr√µes recorrentes)
   - Ciclos e periodicidade
   
2. **An√°lise de s√©ries**:
   - Evolu√ß√£o de m√©tricas ao longo do tempo
   - Mudan√ßas abruptas (changepoints)
   - Autocorrela√ß√£o
   
3. **Agrega√ß√µes temporais**:
   - Por dia, semana, m√™s conforme granularidade
   - M√©dias m√≥veis
   - Taxas de crescimento"""
        else:
            return f"""
**An√°lise Temporal Solicitada (SEM COLUNAS TEMPORAIS EXPL√çCITAS)**

‚ö†Ô∏è **IMPORTANTE**: Dataset N√ÉO possui colunas de datetime expl√≠citas.

Alternativas de an√°lise:
1. Verificar se existe coluna num√©rica representando tempo/sequ√™ncia
2. Analisar a ordem dos dados (se houver signific√¢ncia temporal impl√≠cita)
3. Sugerir que o usu√°rio especifique qual coluna representa tempo
4. Indicar impossibilidade de an√°lise temporal cl√°ssica sem coluna apropriada"""
    
    def _guidelines_correlation(self, ctx: DatasetContext) -> str:
        """Diretrizes para an√°lise de correla√ß√£o."""
        n_numeric = len(ctx.numeric_columns)
        return f"""
**An√°lise de Correla√ß√£o Solicitada**

{n_numeric} colunas num√©ricas dispon√≠veis para an√°lise de correla√ß√£o.

1. **Calcule correla√ß√µes**:
   - Matriz de correla√ß√£o completa (Pearson)
   - Identifique correla√ß√µes fortes (|r| > 0.7)
   - Identifique correla√ß√µes moderadas (0.4 < |r| < 0.7)
   - Identifique correla√ß√µes fracas (|r| < 0.4)

2. **Interprete rela√ß√µes**:
   - Correla√ß√µes positivas (crescem juntas)
   - Correla√ß√µes negativas (inversamente proporcionais)
   - Aus√™ncia de correla√ß√£o linear (r ‚âà 0)

3. **Insights pr√°ticos**:
   - Quais vari√°veis est√£o mais relacionadas?
   - Poss√≠veis rela√ß√µes causa-efeito (cuidado com causalidade!)
   - Redund√¢ncia entre vari√°veis (multicolinearidade)

4. **Visualiza√ß√£o sugerida**:
   - Heatmap de correla√ß√£o
   - Scatter plots para pares de maior correla√ß√£o"""
    
    def _guidelines_outliers(self, ctx: DatasetContext) -> str:
        """Diretrizes para detec√ß√£o de outliers."""
        return f"""
**Detec√ß√£o de Anomalias e Outliers Solicitada**

An√°lise para {len(ctx.numeric_columns)} colunas num√©ricas.

1. **M√©todos de detec√ß√£o**:
   - IQR Method: valores fora de [Q1 - 1.5√óIQR, Q3 + 1.5√óIQR]
   - Z-Score: valores com |z| > 3
   - Percentis: valores nos extremos (<1% ou >99%)

2. **Caracteriza√ß√£o de outliers**:
   - Quantos outliers identificados por coluna?
   - Porcentagem do dataset
   - Valores espec√≠ficos detectados
   - S√£o outliers leg√≠timos ou erros?

3. **Impacto nos dados**:
   - Como outliers afetam m√©dia e desvio padr√£o?
   - Mediana √© mais robusta a outliers
   - Considerar remo√ß√£o, transforma√ß√£o ou investiga√ß√£o?

4. **Recomenda√ß√µes**:
   - Investigar causa dos outliers
   - Validar se s√£o erros de medi√ß√£o
   - Decidir tratamento apropriado"""
    
    def _guidelines_clustering(self, ctx: DatasetContext) -> str:
        """Diretrizes para an√°lise de agrupamentos."""
        return f"""
**An√°lise de Agrupamentos (Clustering) Solicitada**

Dataset com {ctx.row_count:,} linhas e {len(ctx.numeric_columns)} features num√©ricas.

1. **Prepara√ß√£o**:
   - Normaliza√ß√£o/padroniza√ß√£o de features
   - Sele√ß√£o de features relevantes
   - Tratamento de valores ausentes

2. **Identifica√ß√£o de clusters**:
   - Quantos grupos naturais existem?
   - Caracter√≠sticas distintivas de cada cluster
   - Tamanho e propor√ß√£o dos clusters

3. **Interpreta√ß√£o**:
   - O que diferencia os clusters?
   - Perfis t√≠picos de cada grupo
   - Aplicabilidade pr√°tica da segmenta√ß√£o

4. **M√©tricas de qualidade**:
   - Coes√£o intra-cluster (qu√£o similares dentro do grupo)
   - Separa√ß√£o inter-cluster (qu√£o diferentes entre grupos)
   - Silhouette score se dispon√≠vel"""
    
    def _guidelines_comparison(self, ctx: DatasetContext) -> str:
        """Diretrizes para an√°lise comparativa."""
        return f"""
**An√°lise Comparativa Solicitada**

1. **Identifique grupos a comparar**:
   - Baseado em colunas categ√≥ricas ou booleanas
   - Ou segmentos temporais
   - Ou clusters/agrupamentos

2. **Compare estat√≠sticas**:
   - M√©dias, medianas por grupo
   - Desvios padr√£o por grupo
   - Distribui√ß√µes (histogramas lado a lado)

3. **Teste diferen√ßas**:
   - Diferen√ßas absolutas e relativas
   - Signific√¢ncia estat√≠stica (se aplic√°vel)
   - Magnitude do efeito

4. **Visualiza√ß√µes sugeridas**:
   - Boxplots comparativos
   - Barras agrupadas
   - Tabelas de resumo"""
    
    def _guidelines_visualization(self, ctx: DatasetContext) -> str:
        """Diretrizes para solicita√ß√µes de visualiza√ß√£o."""
        return f"""
**Visualiza√ß√£o de Dados Solicitada**

Gr√°ficos dispon√≠veis baseados no dataset:

1. **Para distribui√ß√µes**:
   - Histogramas (vari√°veis num√©ricas)
   - Densidade KDE
   - Boxplots (identificar outliers)

2. **Para rela√ß√µes**:
   - Scatter plots (correla√ß√£o entre 2 vari√°veis)
   - Pairplots (m√∫ltiplas vari√°veis)
   - Heatmap de correla√ß√£o

3. **Para frequ√™ncias**:
   - Gr√°ficos de barras (categorias)
   - Pizza charts (propor√ß√µes)

4. **Para s√©ries temporais**:
   - Line plots (evolu√ß√£o)
   - √Årea plots (tend√™ncias)

**IMPORTANTE**: Descreva o gr√°fico em texto E gere o arquivo de imagem."""
    
    def _guidelines_general(self, ctx: DatasetContext) -> str:
        """Diretrizes para an√°lise geral/explorat√≥ria."""
        return f"""
**An√°lise Explorat√≥ria Geral**

Forne√ßa uma vis√£o completa do dataset:

1. **Overview estrutural**:
   - Quantidade de dados ({ctx.row_count:,} linhas)
   - Tipos de vari√°veis dispon√≠veis
   - Qualidade dos dados (missing values)

2. **Estat√≠sticas resumidas**:
   - Para TODAS as colunas num√©ricas
   - Frequ√™ncias para colunas categ√≥ricas principais

3. **Identifica√ß√£o de padr√µes**:
   - Distribui√ß√µes (sim√©tricas, assim√©tricas, bimodais)
   - Correla√ß√µes aparentes
   - Outliers significativos

4. **Sugest√µes de an√°lise**:
   - Pr√≥ximos passos recomendados
   - An√°lises mais profundas poss√≠veis
   - Potenciais insights a explorar"""
    
    def generate_user_prompt_enhancement(
        self,
        original_query: str,
        dataset_context: DatasetContext,
        historical_context: str = "",
        retrieved_chunks: str = ""
    ) -> str:
        """
        Enriquece o prompt do usu√°rio com contexto relevante.
        
        Args:
            original_query: Pergunta original do usu√°rio
            dataset_context: Contexto do dataset
            historical_context: Hist√≥rico conversacional
            retrieved_chunks: Chunks recuperados via RAG
            
        Returns:
            Prompt enriquecido para a LLM
        """
        prompt = f"**Pergunta do Usu√°rio:** {original_query}\n\n"
        
        if historical_context:
            prompt += f"**Contexto Conversacional:**\n{historical_context}\n\n"
        
        if retrieved_chunks:
            prompt += f"**Informa√ß√µes Anal√≠ticas Dispon√≠veis (RAG):**\n{retrieved_chunks}\n\n"
        
        prompt += f"""**Instru√ß√µes de Resposta:**
- Responda de forma completa e humanizada
- Base sua resposta nos dados reais do dataset
- Cite n√∫meros espec√≠ficos e m√©tricas exatas
- Estruture a resposta de forma clara e organizada
- Finalize com "Se precisar de mais detalhes, √© s√≥ perguntar!\""""
        
        return prompt
    
    def generate_data_types_prompt(self, dataset_context: DatasetContext) -> str:
        """
        Gera prompt especializado para responder sobre tipos de dados.
        Elimina interpreta√ß√£o sem√¢ntica, foca apenas em dtypes t√©cnicos.
        """
        return f"""**AN√ÅLISE PRECISA DE TIPOS DE DADOS**

Dataset: `{dataset_context.file_path}`
Total de colunas: {dataset_context.column_count}

**CLASSIFICA√á√ÉO BASEADA EXCLUSIVAMENTE EM DTYPES:**

**Colunas Num√©ricas ({len(dataset_context.numeric_columns)})**:
{chr(10).join(f'- `{col}` (dtype: {dataset_context.dtypes[col]})' for col in dataset_context.numeric_columns)}

**Colunas Categ√≥ricas ({len(dataset_context.categorical_columns)})**:
{chr(10).join(f'- `{col}` (dtype: {dataset_context.dtypes[col]})' for col in dataset_context.categorical_columns) if dataset_context.categorical_columns else '- Nenhuma coluna categ√≥rica identificada'}

**Colunas Temporais ({len(dataset_context.temporal_columns)})**:
{chr(10).join(f'- `{col}` (dtype: {dataset_context.dtypes[col]})' for col in dataset_context.temporal_columns) if dataset_context.temporal_columns else '- Nenhuma coluna temporal identificada'}

**Colunas Booleanas ({len(dataset_context.boolean_columns)})**:
{chr(10).join(f'- `{col}` (dtype: {dataset_context.dtypes[col]})' for col in dataset_context.boolean_columns) if dataset_context.boolean_columns else '- Nenhuma coluna booleana identificada'}

‚ö†Ô∏è **REGRA CR√çTICA**: 
- N√ÉO interprete semanticamente os nomes das colunas
- Uma coluna "Class" com dtype int64 √© NUM√âRICA, n√£o categ√≥rica
- Use APENAS a informa√ß√£o t√©cnica dos dtypes pandas
- Se todos os dtypes s√£o num√©ricos (int/float), diga que N√ÉO h√° categ√≥ricas

üìã **FORMATO DE RESPOSTA OBRIGAT√ìRIO**:

**Tipos de Dados do Dataset:**

- **Num√©ricas ({len(dataset_context.numeric_columns)})**: [lista todas as colunas]
- **Categ√≥ricas ({len(dataset_context.categorical_columns)})**: [lista todas ou "Nenhuma"]
- **Temporais ({len(dataset_context.temporal_columns)})**: [lista todas ou "Nenhuma"]
- **Booleanas ({len(dataset_context.boolean_columns)})**: [lista todas ou "Nenhuma"]

**Total**: {dataset_context.column_count} colunas no dataset."""


# Inst√¢ncia global para uso facilitado
_dynamic_prompt_generator = DynamicPromptGenerator()


def get_dynamic_prompt_generator() -> DynamicPromptGenerator:
    """Retorna inst√¢ncia global do gerador de prompts din√¢micos."""
    return _dynamic_prompt_generator
