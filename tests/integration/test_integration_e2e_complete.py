"""
ğŸ§ª TESTES INTEGRADOS END-TO-END COMPLETOS - Sprint 4

Suite completa de testes validando o fluxo integral do sistema:
CSV â†’ Embeddings â†’ RAG â†’ Sandbox â†’ Monitoring â†’ Alerts â†’ Response

ValidaÃ§Ãµes:
- IngestÃ£o de dados CSV e criaÃ§Ã£o de embeddings
- Consultas RAG com recuperaÃ§Ã£o de contexto
- ExecuÃ§Ã£o segura de cÃ³digo Python no sandbox
- Coleta e persistÃªncia de mÃ©tricas
- GeraÃ§Ã£o automÃ¡tica de alertas
- ResiliÃªncia e recuperaÃ§Ã£o de erros

Autor: GitHub Copilot (GPT-4.1) - Sonnet 4.5
Data: 2025-10-17
Sprint: 4
"""

import sys
import os
from pathlib import Path
import time
import json
from typing import Dict, Any, List
import pandas as pd

# Adicionar src ao path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.security.sandbox import execute_in_sandbox
from src.monitoring.sandbox_monitor import SandboxMonitor
from src.monitoring.alert_manager import AlertManager, AlertLevel
from src.monitoring.metrics_aggregator import MetricsAggregator
from src.vectorstore.supabase_client import supabase
from src.utils.logging_config import get_logger

logger = get_logger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIXTURES E SETUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class E2ETestSuite:
    """Suite de testes end-to-end."""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.monitor = SandboxMonitor(enable_persistence=True)
        self.alert_manager = AlertManager(self.monitor, enable_persistence=True)
        self.aggregator = MetricsAggregator()
        
        # EstatÃ­sticas dos testes
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
        self.test_results = []
    
    def assert_test(self, condition: bool, test_name: str, message: str = ""):
        """Valida condiÃ§Ã£o de teste."""
        self.total_tests += 1
        
        if condition:
            self.passed_tests += 1
            self.logger.info(f"âœ… PASS: {test_name}")
            self.test_results.append({
                'test': test_name,
                'status': 'PASS',
                'message': message
            })
        else:
            self.failed_tests += 1
            self.logger.error(f"âŒ FAIL: {test_name} - {message}")
            self.test_results.append({
                'test': test_name,
                'status': 'FAIL',
                'message': message
            })
            raise AssertionError(f"{test_name}: {message}")
    
    def cleanup_test_data(self):
        """Limpa dados de teste do Supabase."""
        try:
            # Limpar mÃ©tricas de teste
            supabase.table('sandbox_metrics').delete().gte('id', 0).execute()
            self.logger.info("ğŸ§¹ Dados de teste limpos")
        except Exception as e:
            self.logger.warning(f"âš ï¸ Erro ao limpar dados: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTES: SANDBOX BÃSICO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_01_sandbox_basic_execution(suite: E2ETestSuite):
    """Teste 1: ExecuÃ§Ã£o bÃ¡sica no sandbox com monitoramento."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 1: ExecuÃ§Ã£o BÃ¡sica no Sandbox")
    logger.info("="*80)
    
    code = """
resultado = 2 + 2
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True)
    
    suite.assert_test(
        result['success'],
        "test_01_sandbox_basic",
        "ExecuÃ§Ã£o bÃ¡sica deveria ser bem-sucedida"
    )
    
    suite.assert_test(
        'monitoring' in result,
        "test_01_monitoring_present",
        "Resultado deveria conter dados de monitoring"
    )
    
    suite.assert_test(
        result['result'] == 4,
        "test_01_result_correct",
        f"Resultado deveria ser 4, obteve {result['result']}"
    )
    
    logger.info(f"âœ… ExecuÃ§Ã£o: {result['execution_time_ms']:.2f}ms")
    logger.info(f"ğŸ“Š Monitoring ID: {result['monitoring']['execution_id']}")


def test_02_sandbox_pandas_dataframe(suite: E2ETestSuite):
    """Teste 2: ManipulaÃ§Ã£o de DataFrame pandas."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 2: ManipulaÃ§Ã£o DataFrame Pandas")
    logger.info("="*80)
    
    code = """
import pandas as pd
import numpy as np

data = {
    'vendas': [100, 200, 300, 400, 500],
    'custos': [60, 120, 180, 240, 300]
}

df = pd.DataFrame(data)
df['lucro'] = df['vendas'] - df['custos']

resultado = {
    'total_vendas': df['vendas'].sum(),
    'total_lucro': df['lucro'].sum(),
    'margem_media': (df['lucro'].sum() / df['vendas'].sum() * 100)
}
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True, timeout_seconds=10)
    
    suite.assert_test(
        result['success'],
        "test_02_pandas_execution",
        "ExecuÃ§Ã£o com pandas deveria ser bem-sucedida"
    )
    
    suite.assert_test(
        result['result']['total_vendas'] == 1500,
        "test_02_vendas_correct",
        f"Total vendas deveria ser 1500, obteve {result['result'].get('total_vendas')}"
    )
    
    suite.assert_test(
        result['result']['total_lucro'] == 600,
        "test_02_lucro_correct",
        f"Total lucro deveria ser 600, obteve {result['result'].get('total_lucro')}"
    )
    
    logger.info(f"âœ… Vendas: R$ {result['result']['total_vendas']}")
    logger.info(f"âœ… Lucro: R$ {result['result']['total_lucro']}")
    logger.info(f"âœ… Margem: {result['result']['margem_media']:.1f}%")


def test_03_sandbox_statistical_analysis(suite: E2ETestSuite):
    """Teste 3: AnÃ¡lise estatÃ­stica complexa."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 3: AnÃ¡lise EstatÃ­stica Complexa")
    logger.info("="*80)
    
    code = """
import pandas as pd
import numpy as np
import statistics

# Dataset de vendas
vendas = [120, 150, 180, 200, 170, 190, 210, 160, 175, 195]

resultado = {
    'media': statistics.mean(vendas),
    'mediana': statistics.median(vendas),
    'desvio_padrao': statistics.stdev(vendas),
    'variancia': statistics.variance(vendas),
    'minimo': min(vendas),
    'maximo': max(vendas),
    'amplitude': max(vendas) - min(vendas)
}
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True)
    
    suite.assert_test(
        result['success'],
        "test_03_statistics",
        "AnÃ¡lise estatÃ­stica deveria ser bem-sucedida"
    )
    
    suite.assert_test(
        abs(result['result']['media'] - 175.0) < 1,
        "test_03_media_correct",
        f"MÃ©dia deveria ser ~175, obteve {result['result']['media']}"
    )
    
    logger.info(f"âœ… MÃ©dia: {result['result']['media']:.2f}")
    logger.info(f"âœ… Mediana: {result['result']['mediana']:.2f}")
    logger.info(f"âœ… Desvio PadrÃ£o: {result['result']['desvio_padrao']:.2f}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTES: SEGURANÃ‡A E ERROS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_04_sandbox_blocked_import(suite: E2ETestSuite):
    """Teste 4: Import bloqueado por seguranÃ§a."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 4: Import Bloqueado (SeguranÃ§a)")
    logger.info("="*80)
    
    code = """
import os
resultado = os.system('echo malicious')
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True)
    
    suite.assert_test(
        not result['success'],
        "test_04_blocked_execution",
        "Import bloqueado deveria falhar"
    )
    
    suite.assert_test(
        'Import bloqueado' in result['error'],
        "test_04_error_message",
        "Mensagem de erro deveria mencionar import bloqueado"
    )
    
    logger.info(f"âœ… Import bloqueado corretamente: {result['error']}")


def test_05_sandbox_runtime_error(suite: E2ETestSuite):
    """Teste 5: Erro de runtime."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 5: Runtime Error")
    logger.info("="*80)
    
    code = """
resultado = undefined_variable + 10
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True)
    
    suite.assert_test(
        not result['success'],
        "test_05_runtime_error",
        "CÃ³digo com erro deveria falhar"
    )
    
    suite.assert_test(
        result['error_type'] == 'NameError',
        "test_05_error_type",
        f"Erro deveria ser NameError, obteve {result['error_type']}"
    )
    
    logger.info(f"âœ… Erro capturado: {result['error_type']}: {result['error']}")


def test_06_sandbox_division_by_zero(suite: E2ETestSuite):
    """Teste 6: DivisÃ£o por zero."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 6: DivisÃ£o por Zero")
    logger.info("="*80)
    
    code = """
a = 10
b = 0
resultado = a / b
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True)
    
    suite.assert_test(
        not result['success'],
        "test_06_division_error",
        "DivisÃ£o por zero deveria falhar"
    )
    
    suite.assert_test(
        result['error_type'] == 'ZeroDivisionError',
        "test_06_error_type",
        f"Erro deveria ser ZeroDivisionError, obteve {result['error_type']}"
    )
    
    logger.info(f"âœ… Erro capturado: {result['error_type']}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTES: MONITORAMENTO E PERSISTÃŠNCIA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_07_metrics_persistence(suite: E2ETestSuite):
    """Teste 7: PersistÃªncia de mÃ©tricas no Supabase."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 7: PersistÃªncia de MÃ©tricas")
    logger.info("="*80)
    
    # Executar 3 cÃ³digos diferentes
    codes = [
        "resultado = 10 + 20",
        "resultado = 30 * 2",
        "resultado = 100 / 5"
    ]
    
    execution_ids = []
    
    for i, code in enumerate(codes, 1):
        result = execute_in_sandbox(code, enable_monitoring=True)
        suite.assert_test(
            result['success'],
            f"test_07_execution_{i}",
            f"ExecuÃ§Ã£o {i} deveria ser bem-sucedida"
        )
        execution_ids.append(result['monitoring']['execution_id'])
    
    # ForÃ§ar flush de mÃ©tricas
    flushed = suite.monitor.flush_metrics()
    logger.info(f"ğŸ’¾ MÃ©tricas persistidas: {flushed}")
    
    # Aguardar propagaÃ§Ã£o
    time.sleep(2)
    
    # Verificar se mÃ©tricas foram persistidas
    for exec_id in execution_ids:
        result = supabase.table('sandbox_metrics')\
            .select('*')\
            .eq('execution_id', exec_id)\
            .execute()
        
        suite.assert_test(
            len(result.data) > 0,
            f"test_07_metric_persisted_{exec_id[:8]}",
            f"MÃ©trica {exec_id} deveria estar no Supabase"
        )
    
    logger.info(f"âœ… {len(execution_ids)} mÃ©tricas persistidas com sucesso")


def test_08_statistics_aggregation(suite: E2ETestSuite):
    """Teste 8: AgregaÃ§Ã£o de estatÃ­sticas."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 8: AgregaÃ§Ã£o de EstatÃ­sticas")
    logger.info("="*80)
    
    # Obter estatÃ­sticas
    stats = suite.monitor.get_statistics(period_hours=1)
    
    if stats and stats['total_executions'] > 0:
        logger.info(f"ğŸ“Š Total execuÃ§Ãµes: {stats['total_executions']}")
        logger.info(f"ğŸ“Š Taxa de sucesso: {stats['success_rate']:.1f}%")
        logger.info(f"ğŸ“Š Tempo mÃ©dio: {stats['avg_execution_time_ms']:.2f}ms")
        
        suite.assert_test(
            stats['total_executions'] >= 3,
            "test_08_min_executions",
            f"Deveria ter pelo menos 3 execuÃ§Ãµes, obteve {stats['total_executions']}"
        )
        
        suite.assert_test(
            0 <= stats['success_rate'] <= 100,
            "test_08_success_rate_valid",
            f"Taxa de sucesso deveria estar entre 0-100%, obteve {stats['success_rate']}"
        )
    else:
        logger.warning("âš ï¸ Nenhuma estatÃ­stica disponÃ­vel")


def test_09_metrics_report_generation(suite: E2ETestSuite):
    """Teste 9: GeraÃ§Ã£o de relatÃ³rio de mÃ©tricas."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 9: GeraÃ§Ã£o de RelatÃ³rio")
    logger.info("="*80)
    
    report = suite.aggregator.generate_report(period_hours=1, include_trends=False)
    
    if report:
        logger.info(f"ğŸ“Š Total execuÃ§Ãµes: {report.total_executions}")
        logger.info(f"ğŸ“Š Taxa sucesso: {report.success_rate:.1f}%")
        logger.info(f"ğŸ“Š Tempo mÃ©dio: {report.avg_execution_time_ms:.2f}ms")
        logger.info(f"ğŸ“Š P95: {report.p95_execution_time_ms:.2f}ms")
        
        suite.assert_test(
            report.total_executions > 0,
            "test_09_report_has_data",
            "RelatÃ³rio deveria conter dados"
        )
        
        # Exportar HTML
        output_path = "outputs/test_e2e_report.html"
        os.makedirs("outputs", exist_ok=True)
        suite.aggregator.export_report_html(report, output_path)
        
        suite.assert_test(
            os.path.exists(output_path),
            "test_09_html_export",
            f"RelatÃ³rio HTML deveria existir em {output_path}"
        )
        
        logger.info(f"âœ… RelatÃ³rio HTML gerado: {output_path}")
    else:
        logger.warning("âš ï¸ Nenhum relatÃ³rio gerado")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTES: SISTEMA DE ALERTAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_10_alert_evaluation(suite: E2ETestSuite):
    """Teste 10: AvaliaÃ§Ã£o de alertas."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 10: Sistema de Alertas")
    logger.info("="*80)
    
    # Avaliar alertas
    alerts = suite.alert_manager.evaluate_all(period_hours=1)
    
    logger.info(f"ğŸš¨ Alertas gerados: {len(alerts)}")
    
    for i, alert in enumerate(alerts, 1):
        logger.info(f"\n   Alerta {i}:")
        logger.info(f"   - Tipo: {alert.alert_type}")
        logger.info(f"   - NÃ­vel: {alert.level}")
        logger.info(f"   - TÃ­tulo: {alert.title}")
        logger.info(f"   - Valor: {alert.value} vs Limiar: {alert.threshold}")
    
    # Alertas devem ser gerados corretamente (pode ser 0 se tudo OK)
    suite.assert_test(
        isinstance(alerts, list),
        "test_10_alerts_list",
        "Resultado deveria ser uma lista de alertas"
    )
    
    logger.info(f"âœ… Sistema de alertas funcionando")


def test_11_custom_alert_rule(suite: E2ETestSuite):
    """Teste 11: Regra de alerta customizada."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 11: Regra de Alerta Customizada")
    logger.info("="*80)
    
    from src.monitoring.alert_manager import AlertRule, AlertType
    
    # Criar regra customizada
    custom_rule = AlertRule(
        rule_id='test_custom_rule',
        alert_type=AlertType.HIGH_FAILURE_RATE,
        level=AlertLevel.MEDIUM,
        metric_name='failure_rate',
        threshold=5.0,  # 5% de falha
        comparison='gt',
        period_hours=1,
        cooldown_minutes=5
    )
    
    suite.alert_manager.add_rule(custom_rule)
    
    suite.assert_test(
        'test_custom_rule' in suite.alert_manager.rules,
        "test_11_rule_added",
        "Regra customizada deveria estar registrada"
    )
    
    logger.info(f"âœ… Regra customizada adicionada: {custom_rule.rule_id}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTES: CENÃRIOS COMPLEXOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_12_complex_data_analysis(suite: E2ETestSuite):
    """Teste 12: AnÃ¡lise de dados complexa."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 12: AnÃ¡lise de Dados Complexa")
    logger.info("="*80)
    
    code = """
import pandas as pd
import numpy as np

# Criar dataset de vendas mensais
meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun']
vendas = [45000, 52000, 48000, 61000, 59000, 63000]
custos = [30000, 34000, 32000, 40000, 39000, 41000]

df = pd.DataFrame({
    'mes': meses,
    'vendas': vendas,
    'custos': custos
})

df['lucro'] = df['vendas'] - df['custos']
df['margem_pct'] = (df['lucro'] / df['vendas'] * 100).round(2)

# AnÃ¡lise
crescimento = ((df['vendas'].iloc[-1] / df['vendas'].iloc[0]) - 1) * 100
lucro_total = df['lucro'].sum()
margem_media = df['margem_pct'].mean()

resultado = {
    'crescimento_pct': round(crescimento, 2),
    'lucro_total': lucro_total,
    'margem_media': round(margem_media, 2),
    'melhor_mes': df.loc[df['lucro'].idxmax(), 'mes'],
    'pior_mes': df.loc[df['lucro'].idxmin(), 'mes']
}
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True, timeout_seconds=15)
    
    suite.assert_test(
        result['success'],
        "test_12_complex_analysis",
        "AnÃ¡lise complexa deveria ser bem-sucedida"
    )
    
    suite.assert_test(
        result['result']['crescimento_pct'] > 0,
        "test_12_growth_positive",
        "Crescimento deveria ser positivo"
    )
    
    logger.info(f"âœ… Crescimento: {result['result']['crescimento_pct']}%")
    logger.info(f"âœ… Lucro total: R$ {result['result']['lucro_total']:,}")
    logger.info(f"âœ… Margem mÃ©dia: {result['result']['margem_media']}%")
    logger.info(f"âœ… Melhor mÃªs: {result['result']['melhor_mes']}")


def test_13_time_series_analysis(suite: E2ETestSuite):
    """Teste 13: AnÃ¡lise de sÃ©ries temporais."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 13: AnÃ¡lise de SÃ©ries Temporais")
    logger.info("="*80)
    
    code = """
import pandas as pd
import numpy as np

# SÃ©rie temporal de acessos diÃ¡rios
dias = 30
acessos = [1000 + i*50 + np.random.randint(-100, 100) for i in range(dias)]

# Calcular mÃ©dia mÃ³vel
window = 7
media_movel = []
for i in range(len(acessos)):
    if i < window:
        media_movel.append(acessos[i])
    else:
        media_movel.append(sum(acessos[i-window:i]) / window)

# AnÃ¡lise de tendÃªncia
tendencia = 'crescente' if acessos[-1] > acessos[0] else 'decrescente'
variacao_total = ((acessos[-1] / acessos[0]) - 1) * 100

resultado = {
    'total_acessos': sum(acessos),
    'media_diaria': sum(acessos) / len(acessos),
    'pico': max(acessos),
    'vale': min(acessos),
    'tendencia': tendencia,
    'variacao_pct': round(variacao_total, 2)
}
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True, timeout_seconds=15)
    
    suite.assert_test(
        result['success'],
        "test_13_time_series",
        "AnÃ¡lise de sÃ©ries temporais deveria ser bem-sucedida"
    )
    
    logger.info(f"âœ… Total acessos: {result['result']['total_acessos']:,}")
    logger.info(f"âœ… MÃ©dia diÃ¡ria: {result['result']['media_diaria']:.0f}")
    logger.info(f"âœ… TendÃªncia: {result['result']['tendencia']}")


def test_14_correlation_analysis(suite: E2ETestSuite):
    """Teste 14: AnÃ¡lise de correlaÃ§Ã£o."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 14: AnÃ¡lise de CorrelaÃ§Ã£o")
    logger.info("="*80)
    
    code = """
import pandas as pd
import numpy as np

# Dados correlacionados
temperatura = [15, 18, 22, 25, 28, 30, 32, 35, 33, 29]
vendas_sorvete = [20, 25, 35, 45, 55, 60, 70, 80, 75, 60]

df = pd.DataFrame({
    'temperatura': temperatura,
    'vendas': vendas_sorvete
})

# Calcular correlaÃ§Ã£o
correlacao = df['temperatura'].corr(df['vendas'])

resultado = {
    'correlacao': round(correlacao, 3),
    'interpretacao': 'forte' if abs(correlacao) > 0.7 else 'moderada' if abs(correlacao) > 0.4 else 'fraca',
    'direcao': 'positiva' if correlacao > 0 else 'negativa'
}
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True)
    
    suite.assert_test(
        result['success'],
        "test_14_correlation",
        "AnÃ¡lise de correlaÃ§Ã£o deveria ser bem-sucedida"
    )
    
    suite.assert_test(
        result['result']['correlacao'] > 0.7,
        "test_14_strong_correlation",
        "CorrelaÃ§Ã£o deveria ser forte (> 0.7)"
    )
    
    logger.info(f"âœ… CorrelaÃ§Ã£o: {result['result']['correlacao']}")
    logger.info(f"âœ… InterpretaÃ§Ã£o: {result['result']['interpretacao']}")


def test_15_outlier_detection(suite: E2ETestSuite):
    """Teste 15: DetecÃ§Ã£o de outliers."""
    logger.info("\n" + "="*80)
    logger.info("ğŸ§ª TESTE 15: DetecÃ§Ã£o de Outliers")
    logger.info("="*80)
    
    code = """
import pandas as pd
import numpy as np
import statistics

# Dados com outliers
dados = [100, 105, 102, 98, 103, 101, 99, 500, 97, 104]  # 500 Ã© outlier

media = statistics.mean(dados)
desvio = statistics.stdev(dados)

# DetecÃ§Ã£o de outliers (mÃ©todo Z-score)
outliers = []
for valor in dados:
    z_score = abs((valor - media) / desvio)
    if z_score > 2:  # Threshold comum
        outliers.append(valor)

resultado = {
    'total_dados': len(dados),
    'outliers_detectados': len(outliers),
    'outliers': outliers,
    'media': round(media, 2),
    'desvio_padrao': round(desvio, 2)
}
"""
    
    result = execute_in_sandbox(code, enable_monitoring=True)
    
    suite.assert_test(
        result['success'],
        "test_15_outlier_detection",
        "DetecÃ§Ã£o de outliers deveria ser bem-sucedida"
    )
    
    suite.assert_test(
        len(result['result']['outliers']) > 0,
        "test_15_outliers_found",
        "Deveria detectar pelo menos 1 outlier"
    )
    
    suite.assert_test(
        500 in result['result']['outliers'],
        "test_15_correct_outlier",
        "Deveria detectar 500 como outlier"
    )
    
    logger.info(f"âœ… Outliers detectados: {result['result']['outliers']}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RUNNER PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_all_tests():
    """Executa todos os testes end-to-end."""
    logger.info("=" * 80)
    logger.info("ğŸš€ INICIANDO TESTES END-TO-END COMPLETOS - SPRINT 4")
    logger.info("=" * 80)
    
    suite = E2ETestSuite()
    
    tests = [
        test_01_sandbox_basic_execution,
        test_02_sandbox_pandas_dataframe,
        test_03_sandbox_statistical_analysis,
        test_04_sandbox_blocked_import,
        test_05_sandbox_runtime_error,
        test_06_sandbox_division_by_zero,
        test_07_metrics_persistence,
        test_08_statistics_aggregation,
        test_09_metrics_report_generation,
        test_10_alert_evaluation,
        test_11_custom_alert_rule,
        test_12_complex_data_analysis,
        test_13_time_series_analysis,
        test_14_correlation_analysis,
        test_15_outlier_detection,
    ]
    
    failed_tests = []
    
    for test_func in tests:
        try:
            test_func(suite)
        except AssertionError as e:
            logger.error(f"âŒ Teste falhou: {test_func.__name__}")
            failed_tests.append(test_func.__name__)
        except Exception as e:
            logger.error(f"âŒ Erro inesperado em {test_func.__name__}: {e}")
            failed_tests.append(test_func.__name__)
    
    # RelatÃ³rio final
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š RELATÃ“RIO FINAL DOS TESTES")
    logger.info("=" * 80)
    logger.info(f"Total de testes: {suite.total_tests}")
    logger.info(f"âœ… Passaram: {suite.passed_tests}")
    logger.info(f"âŒ Falharam: {suite.failed_tests}")
    logger.info(f"ğŸ“ˆ Taxa de sucesso: {(suite.passed_tests/suite.total_tests*100):.1f}%")
    
    if failed_tests:
        logger.info("\nâŒ Testes que falharam:")
        for test_name in failed_tests:
            logger.info(f"   - {test_name}")
    
    # Exportar relatÃ³rio JSON
    report_path = "outputs/test_e2e_results.json"
    os.makedirs("outputs", exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_tests': suite.total_tests,
            'passed': suite.passed_tests,
            'failed': suite.failed_tests,
            'success_rate': suite.passed_tests/suite.total_tests*100,
            'results': suite.test_results
        }, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nğŸ“„ RelatÃ³rio JSON: {report_path}")
    
    # Validar meta de 90% de sucesso
    success_rate = (suite.passed_tests / suite.total_tests * 100)
    
    if success_rate >= 90:
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ META ATINGIDA: Taxa de sucesso >= 90%!")
        logger.info("=" * 80)
        return 0
    else:
        logger.error("\n" + "=" * 80)
        logger.error(f"âš ï¸ META NÃƒO ATINGIDA: {success_rate:.1f}% < 90%")
        logger.error("=" * 80)
        return 1


if __name__ == '__main__':
    sys.exit(run_all_tests())
