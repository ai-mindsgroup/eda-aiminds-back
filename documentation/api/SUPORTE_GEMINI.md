# âœ… SIM! A AplicaÃ§Ã£o Aceita Gemini (Google)

**Resposta rÃ¡pida**: âœ… **SIM, totalmente integrado!**

---

## ğŸ¯ Suporte a LLMs na AplicaÃ§Ã£o

A aplicaÃ§Ã£o tem **suporte nativo** para 3 provedores LLM com **fallback automÃ¡tico**:

### **Provedores Suportados**:

1. ğŸš€ **Groq** (PadrÃ£o - Mais rÃ¡pido)
   - Modelo: `llama-3.1-8b-instant`
   - Velocidade: âš¡ Muito rÃ¡pida
   - Gratuito atÃ© 14.400 requisiÃ§Ãµes/dia

2. ğŸ§  **Google Gemini** (Recomendado - Melhor qualidade)
   - Modelo: `gemini-pro`
   - Qualidade: â­â­â­â­â­
   - Gratuito atÃ© 60 requisiÃ§Ãµes/minuto

3. ğŸ’¬ **OpenAI** (Fallback)
   - Modelo: `gpt-3.5-turbo`
   - Qualidade: â­â­â­â­
   - Pago (requer crÃ©ditos)

---

## ğŸ”§ Como Configurar Gemini

### **Passo 1: Obter API Key do Google**

1. Acesse: https://makersuite.google.com/app/apikey
2. Clique em **"Create API Key"**
3. Selecione um projeto ou crie novo
4. Copie a chave gerada

### **Passo 2: Adicionar no `.env`**

Edite o arquivo `configs/.env`:

```env
# JÃ¡ configurado âœ…
SUPABASE_URL=https://ncefmfiulpwssaajybtl.supabase.co
SUPABASE_KEY=eyJhbGc...
DB_PASSWORD=Alder1310

# ADICIONE ESTA LINHA â¬‡ï¸
GOOGLE_API_KEY=AIzaSy...sua_chave_aqui...
```

### **Passo 3: Verificar InstalaÃ§Ã£o**

A biblioteca jÃ¡ estÃ¡ instalada no `requirements.txt`:
```
langchain-google-genai==2.1.9
```

Para garantir:
```powershell
pip install langchain-google-genai
```

---

## ğŸš€ Como Usar

### **OpÃ§Ã£o 1: AutomÃ¡tico (Recomendado)**

O sistema escolhe o melhor provedor disponÃ­vel:

```python
from src.llm.manager import LLMManager

# Inicializa (prioriza: Groq â†’ Google â†’ OpenAI)
manager = LLMManager()

# Usa automaticamente
response = manager.chat("Analise estes dados de fraude...")
print(response.content)
print(f"Usado: {response.provider.value}")  # Ex: "google"
```

### **OpÃ§Ã£o 2: ForÃ§ar Google Gemini**

```python
from src.llm.manager import LLMManager, LLMProvider

# ForÃ§a uso do Google Gemini
manager = LLMManager(preferred_providers=[LLMProvider.GOOGLE])

response = manager.chat("Sua pergunta aqui...")
```

### **OpÃ§Ã£o 3: Com ConfiguraÃ§Ãµes Personalizadas**

```python
from src.llm.manager import LLMManager, LLMConfig

manager = LLMManager()

config = LLMConfig(
    temperature=0.7,  # Mais criativo
    max_tokens=2048,  # Resposta mais longa
    model="gemini-pro"
)

response = manager.chat("Explique anÃ¡lise de fraude", config=config)
```

---

## ğŸ“Š Prioridade de Fallback

Por padrÃ£o, o sistema tenta nesta ordem:

1. **Groq** (mais rÃ¡pido) âš¡
   - Se falhar ou nÃ£o configurado â†’ 

2. **Google Gemini** (melhor qualidade) ğŸ§ 
   - Se falhar ou nÃ£o configurado â†’

3. **OpenAI** (backup confiÃ¡vel) ğŸ’¬

**VocÃª pode mudar a ordem:**
```python
manager = LLMManager(preferred_providers=[
    LLMProvider.GOOGLE,  # Primeiro: Google
    LLMProvider.GROQ,    # Segundo: Groq
    LLMProvider.OPENAI   # Terceiro: OpenAI
])
```

---

## ğŸ§ª Testar Gemini

### **Script de Teste RÃ¡pido**:

Crie `test_gemini.py`:

```python
from src.llm.manager import LLMManager, LLMProvider

# ForÃ§a uso do Gemini
manager = LLMManager(preferred_providers=[LLMProvider.GOOGLE])

# Teste simples
response = manager.chat("OlÃ¡! VocÃª Ã© o Gemini?")
print(f"âœ… Resposta do {response.provider.value}:")
print(response.content)
print(f"\nâ±ï¸ Tempo: {response.processing_time:.2f}s")
print(f"ğŸ”¤ Tokens: {response.tokens_used or 'N/A'}")
```

Execute:
```powershell
python test_gemini.py
```

**SaÃ­da esperada**:
```
âœ… LLM Manager inicializado com provedor ativo: google
âœ… Resposta do google:
Sim, sou o Gemini, um modelo de linguagem grande desenvolvido pelo Google...

â±ï¸ Tempo: 1.23s
ğŸ”¤ Tokens: 42
```

---

## ğŸ” Verificar Status dos Provedores

```python
from src.llm.manager import LLMManager

manager = LLMManager()

# Ver status de todos os provedores
for provider, status in manager._provider_status.items():
    print(f"{provider.value}: {'âœ…' if status['available'] else 'âŒ'} - {status['message']}")
```

**SaÃ­da esperada (com Gemini configurado)**:
```
groq: âŒ - API key nÃ£o configurada
google: âœ… - Google Gemini disponÃ­vel
openai: âŒ - API key nÃ£o configurada
```

---

## ğŸ“š Onde o Gemini Ã© Usado na AplicaÃ§Ã£o

### **1. AnÃ¡lise de CSV** (`src/agent/csv_analysis_agent.py`):
```python
# AnÃ¡lise inteligente de dados
llm_manager = LLMManager()
response = llm_manager.chat(f"Analise este CSV: {data_summary}")
```

### **2. DetecÃ§Ã£o de Fraude** (`src/agent/fraud_detection_agent.py`):
```python
# DetecÃ§Ã£o avanÃ§ada com IA
llm = LLMManager()
analysis = llm.chat(f"Identifique padrÃµes de fraude em: {transactions}")
```

### **3. Chat Inteligente** (API REST):
```python
# Endpoint /chat
llm_manager = LLMManager()
response = llm_manager.chat(user_message)
```

### **4. Sistema RAG** (`src/rag/pipeline.py`):
```python
# Busca semÃ¢ntica + geraÃ§Ã£o de resposta
llm = LLMManager()
answer = llm.chat(f"Com base no contexto: {context}\nPergunta: {query}")
```

---

## ğŸ’° Custos e Limites

### **Google Gemini (Gratuito)**:
- âœ… **60 requisiÃ§Ãµes por minuto**
- âœ… **1.500 requisiÃ§Ãµes por dia**
- âœ… Totalmente gratuito
- ğŸ“– DocumentaÃ§Ã£o: https://ai.google.dev/pricing

### **ComparaÃ§Ã£o**:
| Provedor | Limite Gratuito | Velocidade | Qualidade |
|----------|-----------------|------------|-----------|
| Groq | 14.400/dia | âš¡âš¡âš¡ | â­â­â­ |
| **Gemini** | **1.500/dia** | âš¡âš¡ | â­â­â­â­â­ |
| OpenAI | Pago | âš¡âš¡ | â­â­â­â­ |

---

## ğŸ¯ RecomendaÃ§Ã£o de Uso

### **Para Desenvolvimento**:
```env
# Use Groq (mais rÃ¡pido para testes)
GROQ_API_KEY=sua_chave_groq
GOOGLE_API_KEY=sua_chave_google  # Fallback
```

### **Para ProduÃ§Ã£o**:
```env
# Use Gemini (melhor qualidade)
GOOGLE_API_KEY=sua_chave_google  # Principal
GROQ_API_KEY=sua_chave_groq     # Backup
```

### **Para MÃ¡xima Confiabilidade**:
```env
# Configure os 3
GOOGLE_API_KEY=sua_chave_google
GROQ_API_KEY=sua_chave_groq
OPENAI_API_KEY=sua_chave_openai
```

---

## âœ… Checklist de ConfiguraÃ§Ã£o

- [ ] Obter API Key do Google: https://makersuite.google.com/app/apikey
- [ ] Adicionar `GOOGLE_API_KEY` no `configs/.env`
- [ ] Verificar instalaÃ§Ã£o: `pip install langchain-google-genai`
- [ ] Testar com script de teste
- [ ] Iniciar API completa: `uvicorn src.api.main:app --reload`
- [ ] Verificar logs: deve mostrar "âœ… GOOGLE: Google Gemini disponÃ­vel"

---

## ğŸš¨ SoluÃ§Ã£o de Problemas

### **Erro: "API key nÃ£o configurada"**
âœ… Adicione `GOOGLE_API_KEY` no `.env`

### **Erro: "Biblioteca nÃ£o instalada"**
```powershell
pip install langchain-google-genai google-generativeai
```

### **Erro: "Rate limit exceeded"**
âœ… VocÃª atingiu 60 req/min. Aguarde 1 minuto ou configure fallback.

### **Erro: "Invalid API key"**
âœ… Verifique se copiou a chave completa do Google AI Studio.

---

## ğŸ‰ Resumo

**SIM! A aplicaÃ§Ã£o aceita Gemini com:**
- âœ… Suporte nativo via `LLMManager`
- âœ… Fallback automÃ¡tico
- âœ… ConfiguraÃ§Ã£o simples via `.env`
- âœ… Biblioteca jÃ¡ no `requirements.txt`
- âœ… Usado em toda a aplicaÃ§Ã£o (CSV, Chat, RAG, Fraud Detection)

**PrÃ³ximo passo**: 
1. Pegue sua API key em https://makersuite.google.com/app/apikey
2. Adicione no `.env`
3. Reinicie a aplicaÃ§Ã£o
4. Aproveite o Gemini! ğŸš€

---

**ğŸ”— Links Ãšteis**:
- Google AI Studio: https://makersuite.google.com/app/apikey
- DocumentaÃ§Ã£o Gemini: https://ai.google.dev/docs
- Pricing: https://ai.google.dev/pricing
- Modelos disponÃ­veis: https://ai.google.dev/models/gemini