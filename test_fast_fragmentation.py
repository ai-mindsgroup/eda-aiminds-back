"""
Teste RÃ¡pido do Sistema de FragmentaÃ§Ã£o Otimizado
==================================================

Testes ultra-rÃ¡pidos usando datasets pequenos e versÃµes otimizadas.

Tempo esperado: <5 segundos (vs >30s da versÃ£o com LLM)
"""

import pandas as pd
import numpy as np
from datetime import datetime

from src.llm.fast_fragmenter import fragment_query_fast, FastQueryFragmenter
from src.llm.simple_aggregator import execute_and_aggregate
from src.llm.query_fragmentation import TokenBudget
from src.utils.logging_config import get_logger

logger = get_logger(__name__)


def create_test_dataframe(rows: int = 100, cols: int = 10) -> pd.DataFrame:
    """Cria DataFrame de teste pequeno."""
    data = {}
    for i in range(cols):
        data[f'col_{i}'] = np.random.randn(rows)
    
    # Adiciona colunas com nomes comuns
    data['Amount'] = np.random.uniform(0, 1000, rows)
    data['Time'] = np.arange(rows)
    data['Class'] = np.random.choice([0, 1], rows)
    
    return pd.DataFrame(data)


def test_fast_fragmentation():
    """Testa fragmentaÃ§Ã£o rÃ¡pida."""
    print("\n" + "="*70)
    print("ğŸš€ TESTE 1: FragmentaÃ§Ã£o Ultra-RÃ¡pida (sem LLM)")
    print("="*70)
    
    # Dataset pequeno para teste rÃ¡pido
    df = create_test_dataframe(rows=1000, cols=20)
    
    print(f"ğŸ“Š Dataset: {df.shape[0]} linhas x {df.shape[1]} colunas")
    
    # Teste 1: Query que precisa de poucas colunas
    query1 = "Qual a correlaÃ§Ã£o entre Amount e Time?"
    
    start = datetime.now()
    needs_frag, fragments, reason = fragment_query_fast(
        query=query1,
        df=df,
        token_budget=TokenBudget(max_tokens_per_request=2000)  # Limite baixo para forÃ§ar fragmentaÃ§Ã£o
    )
    elapsed = (datetime.now() - start).total_seconds() * 1000
    
    print(f"\nğŸ“ Query: {query1}")
    print(f"   â±ï¸  Tempo: {elapsed:.1f}ms")
    print(f"   ğŸ”„ Precisa fragmentar: {needs_frag}")
    print(f"   ğŸ’¡ RazÃ£o: {reason}")
    if fragments:
        print(f"   ğŸ“¦ Fragmentos: {len(fragments)}")
        for frag in fragments[:3]:
            print(f"      - {frag.fragment_id}: {len(frag.columns or [])} cols, "
                  f"linhas {frag.row_range}, ~{frag.estimated_tokens} tokens")
    
    # Teste 2: Query que precisa de tudo
    query2 = "Descreva todas as caracterÃ­sticas do dataset"
    
    start = datetime.now()
    needs_frag2, fragments2, reason2 = fragment_query_fast(
        query=query2,
        df=df,
        token_budget=TokenBudget(max_tokens_per_request=2000)
    )
    elapsed2 = (datetime.now() - start).total_seconds() * 1000
    
    print(f"\nğŸ“ Query: {query2}")
    print(f"   â±ï¸  Tempo: {elapsed2:.1f}ms")
    print(f"   ğŸ”„ Precisa fragmentar: {needs_frag2}")
    print(f"   ğŸ’¡ RazÃ£o: {reason2}")
    if fragments2:
        print(f"   ğŸ“¦ Fragmentos: {len(fragments2)}")
    
    print(f"\nâœ… Total: {elapsed + elapsed2:.1f}ms para 2 queries")
    
    return fragments if fragments else fragments2


def test_execution_and_aggregation(fragments):
    """Testa execuÃ§Ã£o e agregaÃ§Ã£o."""
    print("\n" + "="*70)
    print("âš™ï¸  TESTE 2: ExecuÃ§Ã£o e AgregaÃ§Ã£o de Fragmentos")
    print("="*70)
    
    if not fragments:
        print("âš ï¸  Sem fragmentos para testar")
        return
    
    # Cria dataset
    df = create_test_dataframe(rows=1000, cols=20)
    
    start = datetime.now()
    result = execute_and_aggregate(
        df=df,
        fragments=fragments,
        operation="select"
    )
    elapsed = (datetime.now() - start).total_seconds() * 1000
    
    print(f"\nğŸ“Š Resultado:")
    print(f"   âœ… Sucesso: {result['success']}")
    print(f"   ğŸ“¦ Fragmentos processados: {result.get('fragments_success', 0)}/{result.get('fragments_total', 0)}")
    print(f"   ğŸ¯ Tokens usados: {result.get('tokens_total', 0)}")
    print(f"   â±ï¸  Tempo total: {elapsed:.1f}ms")
    print(f"   ğŸ’¾ Cache hits: {result.get('from_cache_count', 0)}")
    
    # Mostra resultado
    if result['success'] and result.get('result') is not None:
        res = result['result']
        if isinstance(res, pd.DataFrame):
            print(f"\n   ğŸ“‹ DataFrame resultante: {res.shape}")
            print(f"      Primeiras linhas:")
            print(res.head(3).to_string(max_cols=5))
        elif isinstance(res, dict):
            print(f"\n   ğŸ“Š EstatÃ­sticas:")
            for key, value in list(res.items())[:5]:
                print(f"      {key}: {value}")
    
    return result


def test_column_extraction():
    """Testa extraÃ§Ã£o rÃ¡pida de colunas."""
    print("\n" + "="*70)
    print("ğŸ” TESTE 3: ExtraÃ§Ã£o de Colunas por PadrÃ£o")
    print("="*70)
    
    fragmenter = FastQueryFragmenter()
    
    test_cases = [
        ("Qual a correlaÃ§Ã£o entre Amount e Time?", ['Amount', 'Time']),
        ("Mostre Amount, Class e V1", ['Amount', 'Class', 'V1']),
        ("AnÃ¡lise de fraudes em Amount", ['Amount']),
    ]
    
    total_time = 0
    for query, expected_cols in test_cases:
        columns = ['Amount', 'Time', 'Class', 'V1', 'V2', 'V3']
        
        start = datetime.now()
        extracted = fragmenter._extract_columns_from_query(query, columns)
        elapsed = (datetime.now() - start).total_seconds() * 1000
        total_time += elapsed
        
        found_expected = all(col in extracted for col in expected_cols)
        
        print(f"\nğŸ“ Query: {query}")
        print(f"   â±ï¸  Tempo: {elapsed:.3f}ms")
        print(f"   ğŸ¯ Colunas esperadas: {expected_cols}")
        print(f"   âœ… Colunas extraÃ­das: {list(extracted) if extracted else 'nenhuma'}")
        print(f"   {'âœ…' if found_expected else 'âš ï¸'} Match: {found_expected}")
    
    print(f"\nâ±ï¸  Tempo total: {total_time:.1f}ms")


def test_performance_comparison():
    """Compara performance: heurÃ­stica vs LLM."""
    print("\n" + "="*70)
    print("âš¡ TESTE 4: ComparaÃ§Ã£o de Performance")
    print("="*70)
    
    df = create_test_dataframe(rows=500, cols=15)
    queries = [
        "Qual a mÃ©dia de Amount?",
        "CorrelaÃ§Ã£o entre Time e Amount",
        "Mostre todas as transaÃ§Ãµes",
    ]
    
    print(f"\nğŸ“Š Dataset: {df.shape}")
    print(f"ğŸ“ Queries: {len(queries)}")
    
    # VersÃ£o rÃ¡pida (heurÃ­stica)
    start_fast = datetime.now()
    for query in queries:
        fragment_query_fast(query, df)
    elapsed_fast = (datetime.now() - start_fast).total_seconds() * 1000
    
    print(f"\nâš¡ VersÃ£o RÃPIDA (heurÃ­stica):")
    print(f"   â±ï¸  Total: {elapsed_fast:.1f}ms")
    print(f"   â±ï¸  MÃ©dia/query: {elapsed_fast/len(queries):.1f}ms")
    
    # Estimativa da versÃ£o com LLM
    estimated_llm_time = len(queries) * 400  # ~400ms por query com LLM
    
    print(f"\nğŸ¢ VersÃ£o COM LLM (estimado):")
    print(f"   â±ï¸  Total estimado: {estimated_llm_time:.1f}ms")
    print(f"   â±ï¸  MÃ©dia/query: {estimated_llm_time/len(queries):.1f}ms")
    
    speedup = estimated_llm_time / elapsed_fast
    print(f"\nğŸš€ SPEEDUP: {speedup:.1f}x mais rÃ¡pido!")


def run_all_tests():
    """Executa todos os testes."""
    print("\n" + "="*70)
    print("ğŸ§ª SISTEMA DE FRAGMENTAÃ‡ÃƒO OTIMIZADO - TESTES RÃPIDOS")
    print("="*70)
    
    start_total = datetime.now()
    
    try:
        # Teste 1: FragmentaÃ§Ã£o
        fragments = test_fast_fragmentation()
        
        # Teste 2: ExecuÃ§Ã£o e AgregaÃ§Ã£o
        if fragments:
            test_execution_and_aggregation(fragments)
        
        # Teste 3: ExtraÃ§Ã£o de colunas
        test_column_extraction()
        
        # Teste 4: ComparaÃ§Ã£o de performance
        test_performance_comparison()
        
        elapsed_total = (datetime.now() - start_total).total_seconds()
        
        print("\n" + "="*70)
        print("âœ… TODOS OS TESTES CONCLUÃDOS COM SUCESSO")
        print("="*70)
        print(f"â±ï¸  Tempo total: {elapsed_total:.2f}s")
        print(f"ğŸ¯ Performance: {'EXCELENTE' if elapsed_total < 5 else 'BOA' if elapsed_total < 10 else 'ACEITÃVEL'}")
        
        return True
        
    except Exception as e:
        elapsed_total = (datetime.now() - start_total).total_seconds()
        
        print("\n" + "="*70)
        print("âŒ ERRO NOS TESTES")
        print("="*70)
        print(f"Erro: {str(e)}")
        print(f"â±ï¸  Tempo atÃ© falha: {elapsed_total:.2f}s")
        
        import traceback
        traceback.print_exc()
        
        return False


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1)
